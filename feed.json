{
    "version": "https://jsonfeed.org/version/1",
    "title": "莫胜文",
    "subtitle": "what will be, will be.",
    "icon": "https://i.merore.com/images/favicon.ico",
    "description": "",
    "home_page_url": "https://i.merore.com",
    "items": [
        {
            "id": "https://i.merore.com/xv6/xv6-book-translate/chapter-6-locking/",
            "url": "https://i.merore.com/xv6/xv6-book-translate/chapter-6-locking/",
            "title": "Chapter 6 锁",
            "date_published": "2022-11-05T03:09:07.000Z",
            "content_html": "<h1 id=\"chapter-6-锁\"><a class=\"anchor\" href=\"#chapter-6-锁\">#</a> Chapter 6 锁</h1>\n<p>包括 xv6 在内的大多数内核，都在交错执行多个任务。交错执行的一种原因是多处理器硬件：多 CPU 独立执行，例如 xv6 的 RISC-V。这些 CPU 共享物理内存，xv6 利用共享来维护 CPU 读写的数据结构。这种共享造成一种情况是，一个 CPU 正在读数据而同时另一个 CPU 正在更新数据；或是多个 CPU 在同时更新相同的数据；如果不仔细设计的话这种并行访问会造成不正确的结果并破坏数据结构。即使在单一处理器上，内核可能在多个线程之间切换，造成这些执行也是交错的。最后，如果在一个错误的时间发生设备中断，中断处理程序可能会损害数据结构。并发指的就是由于多处理器并行，线程切换，或者中断，多指令流交错执行。</p>\n<p>内核中充满了并发访问的数据。例如，两个 CPU 可能同时调用  <code>kalloc</code> ，从而同时从空闲列表弹出表头。内核设计允许一些并发，因为这样能够通过并行提高性能并提高响应速度。然而，因为并发的问题，内核设计者需要话费大量的时间来证明他们的正确性。有很多方法可以得到正确的代码，有一些更容易推理。并发下的正确策略和抽象被称为并发控制技术。</p>\n<p>xv6 根据情况使用了一些并发控制技术。本章将会聚焦于广泛使用的一种并发控制技术， <code>锁</code> 。锁提供互斥，确保同一时间只有一个 CPU 持有锁。如果一个程序员为每个个共享的数据关联了一个锁，并在每次使用数据时持有该锁，则这个数据只会同时被一个 CPU 所使用。在这个方案下，我们可以看到所保护了数据。虽然锁是如此容易理解的并发控制机制，但锁的缺点是降低了性能，因为并行的操作被实际上顺序执行了。</p>\n<p>剩下的章节会介真实情况绍 xv6 为什么需要锁，xv6 如何实现和使用锁。<br />\n<img data-src=\"https://s2.loli.net/2022/11/05/uFRcD1x9HjMZyBs.png\" alt=\"22834193-aa127715b246d58a.png\" /></p>\n<h2 id=\"条件竞争\"><a class=\"anchor\" href=\"#条件竞争\">#</a> 条件竞争</h2>\n<p>有一个例子说明我们为什么需要锁，考虑两个进程在不同的 CPU 上调用  <code>wait</code> 。 <code>wait</code>  释放子进程的内存。因此，在每个 CPU 上，内核将会调用  <code>kfree</code>  释放子进程的页。内核分配器维护了一个  <code>kallloc（）</code>  从空闲列表弹出表头， <code>kfree（）</code>  将页压入空闲列表。如果为了性能最优，我们可能希望两个进程能并行的执行  <code>kfree</code>  而不需要等待，但这不是 xv6  <code>kfree</code>  的正确实现。</p>\n<p>如上图所示，链表在内存中是被两个 CPU 共享的，他们通过 load 和 store 指令操作链表。（真实情况处理器中有缓存，但行为上就是多处理器共享单一内存）如果没有并发请求，你可能会为链表实现一个这样的  <code>push</code>  操作。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">element</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  <span class=\"token number\">2</span>     <span class=\"token keyword\">int</span> data<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  <span class=\"token number\">3</span>     <span class=\"token keyword\">struct</span> <span class=\"token class-name\">element</span><span class=\"token operator\">*</span> next<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>  <span class=\"token number\">4</span> <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>  <span class=\"token number\">5</span> </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>  <span class=\"token number\">6</span> strcut element<span class=\"token operator\">*</span> list <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>  <span class=\"token number\">7</span> </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  <span class=\"token number\">8</span> <span class=\"token keyword\">void</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>  <span class=\"token number\">9</span> <span class=\"token function\">push</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> data<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre> <span class=\"token number\">10</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre> <span class=\"token number\">11</span>     <span class=\"token keyword\">struct</span> <span class=\"token class-name\">element</span><span class=\"token operator\">*</span> l<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre> <span class=\"token number\">12</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre> <span class=\"token number\">13</span>     l <span class=\"token operator\">=</span> <span class=\"token function\">malloc</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">sizeof</span> <span class=\"token operator\">*</span>l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre> <span class=\"token number\">14</span>     l<span class=\"token operator\">-></span>data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre> <span class=\"token number\">15</span>     l<span class=\"token operator\">-></span>next <span class=\"token operator\">=</span> list<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre> <span class=\"token number\">16</span>     list <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre> <span class=\"token number\">17</span> <span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p><img data-src=\"https://s2.loli.net/2022/11/05/LQs31AtDBiSHdER.png\" alt=\"22834193-6c9c0eac7c1d000c.png\" /></p>\n<p>如果在隔离的环境中执行的话，这个实现是没问题的。然而，如果这段代码有多个在同时执行就不对了。如果两个 CPU 都在执行 push 操作，可能同时执行到第 15 行，然后在执行 16 行，这会导致错误的结果。当两个操作发生时，后一个操作会覆盖前一个导致前一个丢失。</p>\n<p>丢失的第 16 行操作被称为 <code>条件竞争（race condition）</code> 。条件竞争指的是内存被并发访问并且至少有一个访问是写操作。竞争通常是一个 bug，无论是操作丢失或者读了尚未完成更新的数据。竞争的结果取决与 CPU 具体执行的时间和内存中操作的顺序，这会使竞争造成的错误难以重现和纠错。例如，在调试时加入打印语句可能会改变程序执行的时间，从而让竞争消失。</p>\n<p>通过采用锁来避免竞争。锁确保互斥，同时只有一个 CPU 能在执行 push 中的敏感操作。这会使上面的场景变得不可能。正确的加锁版本的代码只需要很少几行。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">element</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  <span class=\"token number\">2</span>     <span class=\"token keyword\">int</span> data<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  <span class=\"token number\">3</span>     <span class=\"token keyword\">struct</span> <span class=\"token class-name\">element</span><span class=\"token operator\">*</span> next<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>  <span class=\"token number\">4</span> <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>  <span class=\"token number\">5</span> </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>  <span class=\"token number\">6</span> strcut element<span class=\"token operator\">*</span> list <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>  <span class=\"token number\">7</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">lock</span> listlock<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  <span class=\"token number\">8</span> </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>  <span class=\"token number\">9</span> <span class=\"token keyword\">void</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre> <span class=\"token number\">10</span> <span class=\"token function\">push</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> data<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre> <span class=\"token number\">11</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre> <span class=\"token number\">12</span>     <span class=\"token keyword\">struct</span> <span class=\"token class-name\">element</span><span class=\"token operator\">*</span> l<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre> <span class=\"token number\">13</span>     l <span class=\"token operator\">=</span> <span class=\"token function\">malloc</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">sizeof</span> <span class=\"token operator\">*</span>l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre> <span class=\"token number\">14</span>     l<span class=\"token operator\">-></span>data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre> <span class=\"token number\">15</span>     <span class=\"token function\">acquire</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>listlock<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre> <span class=\"token number\">16</span>     l<span class=\"token operator\">-></span>next <span class=\"token operator\">=</span> list<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre> <span class=\"token number\">17</span>     list <span class=\"token operator\">=</span> l<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre> <span class=\"token number\">18</span>     <span class=\"token function\">release</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>listlock<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre> <span class=\"token number\">19</span> <span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>在  <code>acquire</code>  和  <code>release</code>  之间的指令经常被称为临界区。锁通常被称为保护列表。</p>\n<p>当我们说锁保护数据的时候，我们实际的意思是保护一些作用于数据上的不变量（比如链表例子中的 l，l-&gt;next）。这些不变量是维护数据结构的属性。通常，操作的正确性取决于操作开始的时候，这些不变量是否是预期的。有些操作可能会暂时修改不变量，但必须在完成之前重建。例如，在这个链表的例子里，不变量是指向链表的第一个指针 l 和这个元素的 next。push 操作在 17 行违反了这个不变量。 将 l 指向了下一个元素。由于第二个 CPU 执行的代码依赖于这些不变量，就发生了条件竞争。正确使用锁，可以保证同一时间只有一个 CPU 能够操作临界区的数据。这样当数据结构的不变量不成立时，CPU 不会操作数据结构。</p>\n<p>你可以认为锁串行了临界区，因此保存了不变量。你还可以将受锁保护的临界去视为原子性的。这样每个人看到的都是完整的修改，而不会是片段。</p>\n<p>虽然正确的使用锁可以矫正代码，但锁限制了性能。例如，如果两个进程并发调用  <code>kfree</code> ，锁将这两个调用串行，我们不会因为两个 CPU 而带来任何的好处。如果多个进程同时想要一个锁，就是冲突，或者出现锁争用。以链表为例，内核可能为每个 CPU 维护一个 空闲列表，如果一个 CPU 的空闲列表为空，必须从其他 CPU 偷来内存。其他的使用场景或许还需要更复杂的设计。</p>\n<p>锁的位置对性能也至关重要。例如，我们可以把  <code>acquire</code>  向前移动：这可能会降低性能，因为我们把 malloc 也串行了。Using locks 一节提供了在何处插入  <code>acquire</code>  和  <code>release</code>  的指南。</p>\n<h2 id=\"code-locks\"><a class=\"anchor\" href=\"#code-locks\">#</a> Code: locks</h2>\n<p>xv6 有两种锁， <code>spinlock</code>  和  <code>sleep-locks</code> 。我们从 spinlocks 开始。xv6 用 <code>struct spinlock</code>  表示 spinlock。其中一个重要的字段是  <code>locked</code> ，当锁被持有时是一个非 0 值，否则是 0 值。逻辑上，xv6 应该以这种方式请求一个锁。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token number\">1</span> <span class=\"token keyword\">void</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>  <span class=\"token number\">2</span> <span class=\"token function\">acquire</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">struct</span> <span class=\"token class-name\">spinlock</span><span class=\"token operator\">*</span> lk<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>  <span class=\"token number\">3</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>  <span class=\"token number\">4</span>     <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>  <span class=\"token number\">5</span>         <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>lk<span class=\"token operator\">-></span>locked <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>  <span class=\"token number\">6</span>             lk <span class=\"token operator\">-></span> locked <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>  <span class=\"token number\">7</span>             <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>  <span class=\"token number\">8</span>         <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>  <span class=\"token number\">9</span>     <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre> <span class=\"token number\">10</span> <span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>不幸的是，这个实现并不能保证多核互斥。如果两个 CPU 都走到了第 5 行，看到  <code>lk-&gt;locked</code>  是 0，来你跟着都会持有这个锁，这违反了互斥性。我们需要让第 5 行和第 6 行成为一个原子操作。</p>\n<p>由于锁被广泛使用，多核处理器通常会提供一些指令来实现 25,26 行的原子性。RISC-V 中，这个指令是  <code>amoswap r, a</code> 。 <code>amoswp</code>  从地址 a 出值，将 r 寄存器的内容写到这个地址，并把这个值放到 r 寄存器。这样的话，就交换了寄存器和地址的内容。它以原子的方式执行这个操作，使用特殊的硬件防止其他 CPU 对该地址进行读写。</p>\n<p>xv6 的  <code>acquire</code>  使用了 C 库中的  <code>__sync_lock_test_and_set</code> 。它归结为  <code>amoswap</code>  指令。它返回 lk-&gt;locked 中的旧值。 <code>acquire</code>  函数在一个循环中包装 swap，多次尝试（spinning）直到获取锁。每次迭代都会检查以前的旧值，如果以前的值是 0, 我们就可以获得这个锁，并且交换会把  <code>lk-&gt;locked</code>  设置为 1。如果以前的值是 1, 说明其他 CPU 持有这个锁，事实上我们将 1 交换到 lk-&gt; locked 也不会改变它的值。</p>\n<p>一旦锁被获取， <code>acquire</code>  会进行记录获取锁的 CPU 用于 debug。lk-&gt;cpu 字段被锁保护必须由持有锁时进行变更。</p>\n<p><code>release</code>  是对  <code>acquire</code>  的相对操作：清除  <code>lk-&gt;cpu</code>  字段并释放锁。从概念上讲，release 只需要把 lk-&gt;locked 置为 0。但是 C 标准允许将赋值操作实现为多条存储指令，因此对于并发来说，一条赋值语句可能并不是原子的。相反，release 使用 c 库 的  <code>__sync_lock_release</code>  执行原子操作。这个操作也属于  <code>amoswap</code>  指令的一部分。</p>\n<h2 id=\"使用锁\"><a class=\"anchor\" href=\"#使用锁\">#</a> 使用锁</h2>\n<p>xv6 在多个地方使用锁来避免条件竞争。就像上边说的， <code>kalloc</code>  和  <code>kfree</code>  是一个好的例子。尝试练习 1,2 看看如果省略了锁会发生什么。你可能会发现很触发不正确的行为，表明通过代码很难可靠的测试锁和竞争带来的错误。xv6 不太可能存在竞争。</p>\n<p>使用锁的一个难点在于决定使用多少锁，以及每个锁应该保护哪些数据和不变量。这里有几个基本原则。首先，如果一个变量被一个 CPU 写操作时，另一个 CPU 也能读写它，应该使用锁让这两个操作不重叠。其次，记住锁是保护不变量的，如果一个不变量出现在内存多个位置，通常它们都需要被一个锁保护来维护不变量。</p>\n<p>上边说的都是所需要被使用的情况，没说锁不需要使用的地方，对效率来说不过多使用锁是很重要的，因为锁会降低并行度。如果并行不重要的话，可以安排只有一个线程并不需要担心锁。一个简单的内核可以做到这一点，通过在进入内核时获取一个锁并在退出内核时释放锁（尽管像 pipe read 或者 wait 这种系统调用会出问题）。许多单处理器操作系统通过这种方法运行在多处理器上，这种方法有时被称为 <code>big kernel lock</code> 。但是这种方法牺牲了并行性，同时只能有一个 CPU 工作在内核态。如果内核有很重的计算任务，使用更多的细粒度锁会更有效，这样内核就可以在多 CPU 上并行执行。</p>\n<p>xv6 的  <code>kalloc</code>  就是一个粗粒度锁的例子。分配器有一个锁保护的列表。如果不同 CPU 上的进程同时想分配页，都必须通过自旋等待获取锁。自旋会降低性能，因为自旋本身是没用的操作。如果因为锁的争用而浪费了大量的时间，可以通过修改分配器的设计，提供多个空闲列表来提高性能。每个 CPU 都有自己的空闲列表，以真正的允许并行。（译者注：很多降低锁竞争的常规手段，称为 per-CPU，广泛用于内存分配）。</p>\n<p>一个细粒度锁的例子是，xv6 中每个文件的有一个锁。这样不同的进程操作不同的文件可以同时进行而不必互相等待。文件锁可以做的更细粒度，比如在同一个文件的不同位置上锁。总的来说，锁的粒度主要是出于性能和复杂度两方面考虑。</p>\n<p>后续的章节会提到锁处理并发的例子。</p>\n<h2 id=\"死锁和顺序锁\"><a class=\"anchor\" href=\"#死锁和顺序锁\">#</a> 死锁和顺序锁</h2>\n<p>如果内核代码的路径上需要同时持有多个锁，那么这些锁保持一个相同的顺序是很重要的。否则就会有 <code>死锁</code> 的可能。让我们看看 xv6 中的两处需要 A，B 锁的代码，第一处的锁顺序是先 A 后 B，第二处是先 B 后 A。假设线程 T1，在第一处先获取了 A 锁，线程 T2 在第二处获取了 B 锁。接下来，T1 会尝试获取 B，T2 会尝试获取 A。这两个操作将无限阻塞下去因为他们都需要对方持有的锁，且不会释放自己持有的锁。为了避免死锁，所有的代码都应该以相同的顺序来获取锁。需要全局锁顺序意味着锁是函数也是函数约定的一部分：调用着必须按照锁的顺序以相同的顺序进行函数调用。</p>\n<p>由于  <code>sleep</code>  工作，xv6 可能有许多长度为 2 的顺序锁。例如， <code>consoleintr</code>  是一个处理输入字符的中断。当新的行到达时，所有等待控制台输入的程序都应该被唤醒。为了达到这个目的， <code>consoleintr</code>  唤醒时会持有一个  <code>cons.lock</code> ，这会获取等待线程的锁并唤醒它。因此，避免死锁的是在获取任何线程之前先获取  <code>cons.lock</code> 。xv6 中的文件系统拥有最长的锁调用链。例如，同时创建文件需要持有目录的锁，一个文件的 inode 锁，一个磁盘块 buffer 的锁，一个磁盘驱动锁 <code>vdisk_lock</code>  和调用的进程的锁 <code>p-&gt;lock</code> 。为了避免死锁，文件系统代码必须按上边的顺序持有锁。</p>\n<p>遵守全局避免死锁的原则可能会非常困难。有时锁的顺序和程序的逻辑顺序是冲突的，比如，模块 M1 调用 模块 M2，但锁的顺序是先锁 M2 再锁 M1。还有些情况是我们事先并不知道这些锁是什么，我们只有在获取到一个锁的时候才能知道下一个要获取的锁是什么。这种情况会出现在文件系统中查找路径文件，和 <code>wait</code> ， <code>exit</code>  等代码查找子进程。最终，死锁与否还是受锁粒度的约束，因为更多的锁就会有更多死锁的可能。避免死锁也是内核实现的一个主要因素。</p>\n<h2 id=\"锁和中断处理\"><a class=\"anchor\" href=\"#锁和中断处理\">#</a> 锁和中断处理</h2>\n<p>有些 xv6 spinlocks 保护的数据被线程和中断处理程序同时持有。例如当内核县城在  <code>sys_sleep</code>  读取  <code>ticks</code>  时， <code>clockintr</code>  时钟中断可能增加  <code>ticks</code>  的值。 <code>tickslock</code>  会将这两个操作串行。</p>\n<p>锁和中断的联系会产生潜在的问题。假设  <code>sys_sleep</code>  获取了  <code>tickslock</code> ，CPU 产生了一个时钟中断。 <code>clockintr</code>  会尝试获取  <code>tickslock</code> ，发现它被别人持有，就会等待释放。这种情况下， <code>tickslock</code>  将永远不会释放：只有  <code>sys_sleep</code>  能够释放它，但是  <code>sys_sleep</code>  直到  <code>clockintr</code>  返回都不会再继续运行。所以 CPU 就死锁了，任何需要锁的代码也都冻结。</p>\n<p>为了避免这种情况，中断处理程序使用的 spinlock 不能在中断开启的情况下被持有。xv6 更保守一些，当 CPU 持有锁的时候，xv6 总是禁用这个 CPU 上的中断。中断可能发生在其它 CPU 上，所以中断需要的锁可以等待其他不在同一个 CPU 上的线程释放。</p>\n<p>当 CPU 不在持有锁时，xv6 重新启用中断；这里必须做一点标记以应对临界区嵌套的情况。 <code>acquire</code>  调用  <code>push_off</code> ， <code>release</code>  调用  <code>pop_off</code>  来跟踪锁的层级。当计数器到 0 的时候， <code>pop_off</code>  恢复最外层的中断状态。 <code>intr_off</code>  和  <code>intr_on</code>  两个函数在 RISC-V 中用于禁用和开启中断。</p>\n<p>在  <code>acquire</code>  中，在设置  <code>lk-&gt;locked</code>  之前关闭中断很重要。如果两个反过来，在持有锁和关闭中断之间会有时间间隙，如果不幸的话，时钟中断将让整个系统死锁。同样，在释放锁只有调用 <code>pop_off</code>  也同样重要。</p>\n<h2 id=\"指令和内存排序\"><a class=\"anchor\" href=\"#指令和内存排序\">#</a> 指令和内存排序</h2>\n<p>认为程序的执行顺序和源码语句的出先方式是一样的这是很自然的。然而，许多编译器和 CPU 会为了性能而乱序执行。如果一个指令需要许多时钟周期来完成，CPU 可能会提前发出指令，以便和其他指令重叠从而避免 CPU 停顿。例如，CPU 可能注意到两条连续的互不干扰的指令 A 和 B。如果 B 的输入比 A 先准备好，CPU 可能会先开始执行 B，或者重叠执行 A B。编译器可能进行同样的重排序操作。</p>\n<p>编译器和 CPU 在重排序时遵循以下的原则以确保不会修改正确的指令结果。然而，这些原则是允许并发的情况下改变执行结果的，并在多核处理器上很容易就造成错误的结果。CPU 的排序规则也被称谓  <code>memory model （内存模型）</code> 。</p>\n<p>例如  <code>push</code>  中的代码， 如果 CPU 将第四行的 store 操作移动到  <code>release</code>  之后，将会造成很严重的错误。如果这样的重排序发生，就会在获取锁之前出现一个窗口时间，发现 list 有变动，并且发现没有初始化的 <code>list-&gt;next</code> 。</p>\n<p>为了告诉硬件和编译器不要进行这种优化，xv6 在  <code>acquire</code>  和  <code>release</code>  中使用  <code>__sync_synchronize()</code> 。 <code>__sync_synchronize()</code>  是一个 <code>memory barrier（内存屏障）</code> 。它告诉编译器和 CPU 不要跨屏障进行 <code>load</code>  和 <code>store</code> 。由于 xv6 使用锁访问共享数据，所以 xv6 在大多数情况下强制排序。</p>\n<h2 id=\"休眠锁\"><a class=\"anchor\" href=\"#休眠锁\">#</a> 休眠锁</h2>\n<p>有时，xv6 需要长时间的持有一个锁，比如文件系统会在读写硬盘上的内容时持有锁，而这些操作往往要花费数十毫米。长时间持有一个 spinlock 会导致浪费，因为在 spin 期间 CPU 做不了任何事情。spinlock 的另一个缺陷是在持续期间内不能让出 CPU。我们想要做的就是如果一个因为一个锁在等待磁盘操作的花，一个进程可以使用 CPU。持有 spinlock 期间让出 CPU 是不合法的，因为如果其他进程获取这个锁会导致整个操作系统死锁。因此，我们需要一种锁，当执行 acquire 的时候让出 CPU。并在持有锁的时候允许让出 CPU。</p>\n<p>xv6 提供了这样一种锁  <code>sleep-locks</code>  以在等待时让出 CPU。第七章将详细讲解使用的技术。从上层来讲，一个   <code>sleep-lock</code>  拥有一个让  <code>spinlock</code>  保护的字段  <code>locked</code> 。 <code>acquiresleep</code>  将调用 sleep 以让出 CPU，并释放 spinlock。结果就是当执行  <code>acquiresleep</code>  的时候，其他线程可以执行。</p>\n<p>由于  <code>sleep-locks</code>  启用了中断，所以不能被用于中断处理中。因为 <code>acquiresleep</code>  可能会让出 CPU，sleep-lock 不能在 spinlock 的临界区内使用。spin-locks 适用于短临界区，因为等待总会浪费 CPU。而 sleep-lock 在耗时较长的操作上表现很好。</p>\n<h2 id=\"real-world\"><a class=\"anchor\" href=\"#real-world\">#</a> Real world</h2>\n<p>尽管对并发原语和并行进行了多年的研究，但使用锁编程仍然面临巨大的挑战。将锁隐藏在更高级别的结构上是很好的做法例如同步队列。如果你的程序使用了锁，最好使用一些工具来检测条件竞争，因为你很容易忽略掉给一些不变量加锁的情况。</p>\n<p>许多操作系统支持 POSIX 献策灰姑娘模型（pthreads），这允许用户进程在不同 CPU 上运行多个线程。Pthreads 支持用户级别的锁，内存屏障等等。Pthreads 需要操作系统的支持。例如，如果一个线程因为系统调用阻塞了，另一个相同的进程可以运行在这个 CPU 上。另外，如果一个 pthreads 修改了它的进程地址空间，内核必须让这个进程上的其他线程更新以对地址空间的变更做出反应。</p>\n<p>不使用原子指令也可以实现锁，但是代价很昂贵，所以许多操作系统使用原子指令。</p>\n<p>如果多个 CPU 同时竞争一个锁，那么锁的代价是很昂贵的。如果一个 CPU 在自己的缓存中持有一个锁，当另一个也需要持有这个锁时，更新缓存的原子指令必须将缓存进行在两个 CPU 之间进行复制，这样可能导致其他缓存失效。从其他 CPU 的缓存中获取缓存行的开销可能比从本地缓存中获取的开销高几个数量级。</p>\n<p>为了避免锁昂贵的开销，一些操作系统使用无锁的数据结构和算法。例如，链表的查询不需要锁，并且使用原子指令对链表进行插入。比起锁，无锁程序会更复杂，比如，它必须考虑指令和内存重排。锁程序已经很困难了，所以 xv6 避免无锁带来更复杂的问题。</p>\n<p>总结：</p>\n<ol>\n<li>锁本身的实现依赖硬件提供的原子性的操作</li>\n<li>锁保护一些不变量，这些不变量会在操作过程中发生变动并最终稳定，这些过程就叫做临界区</li>\n<li>避免死锁的一种方法是对于多个锁连续持有的情况下，需要固定顺序</li>\n<li>spinlock 需要关中断，用于让 CPU 绝对安全的持有共享资源</li>\n<li>并发问题的原因之一是一份资源被多 CPU 共享造成的，对这些共享资源操作可以加锁，也可以设计成 per-cpu 的无锁模式</li>\n<li>注意锁和中断处理的互相作用而造成的死锁，要考虑持有锁后如果发生中断，是否会死锁，是否要关中断。</li>\n<li>由于锁操作本身涉及的是多个 CPU 对共享资源的竞争，所以需要通过内存屏障来保证顺序执行。让锁正确的被 CPU 持有。</li>\n<li>CPU 乱序执行只会对并行结果有影响，当我们通过锁保护了临界区操作后，就不再需要内存屏障了，所以一般用户态编程不会使用内存屏障，而大多数基础库，尤其是涉及线程操作的会使用内存屏障。</li>\n</ol>\n",
            "tags": [
                "xv6",
                "xv6-book中文翻译"
            ]
        },
        {
            "id": "https://i.merore.com/xv6/xv6-book-translate/chapter-5-interrupts/",
            "url": "https://i.merore.com/xv6/xv6-book-translate/chapter-5-interrupts/",
            "title": "Chapter 5 中断和设备驱动",
            "date_published": "2022-11-04T11:41:55.000Z",
            "content_html": "<h1 id=\"chapter-5-中断和设备驱动\"><a class=\"anchor\" href=\"#chapter-5-中断和设备驱动\">#</a> Chapter 5 中断和设备驱动</h1>\n<p><code>驱动</code>  是操作系统中的一段用于管理特殊设备的代码：它配置设备的硬件，告诉设备处理工作，处理产生的中断，并与可能正在等待来自设备 IO 的进程进行交互。驱动代码可能很棘手，因为驱动可能和设备并发执行。除此之外，驱动必须理解设备硬件接口，这可能会非常复杂。</p>\n<p>需要操作系统注意的设备通常都会产生中断，这是陷阱的一种。当设备中断产生时，内核陷阱处理程序识别并调用设备中断处理程序。在 xv6 里，这种处理在  <code>devintr</code> 。</p>\n<p>许多设备驱动在两种上下文环境中执行：上半部分是进程内核线程，下半部分是中断处理。上半部分是通过一些  <code>read</code>  或  <code>write</code>  系统调用，让设备进行 IO。这些代码可能会要求硬件执行一个操作。然后代码会等待操作完成。最终设备会完成这个工作并产生一个中断。驱动的中断处理，作为下半部分，弄清楚哪个操作完成了，唤醒合适的等待线程，并告诉硬件开始等待执行下一个操作。</p>\n<h2 id=\"code-控制台输入\"><a class=\"anchor\" href=\"#code-控制台输入\">#</a> Code: 控制台输入</h2>\n<p>控制台驱动（console.c）是一个简单的驱动结构。控制台驱动通过连接到 RISC-V 上的 UART 串行端口硬件，接收来自用户的输入的字符。控制台驱动每次接收一行输入，并处理特殊的输入字符，例如  <code>backspace</code>  和  <code>control-u</code> 。像 shell 这样的用户进程，使用  <code>read</code>  系统调用从控制台中获取输入的行。当你在 QEMU 中向 xv6 进行输入时，你的按键会通过 QEMU 模拟的 UART 硬件传送到 xv6 中。</p>\n<p>驱动程序进行通信交互的 UART 硬件是 QEMU 模拟的 16550 芯片。在真实的计算机上，16550 芯片会管理连接到终端和其他计算机的 RS232 串行链路。当运行 QEMU 的时候，你的键盘和显示都链接到 QEMU 上了。</p>\n<p>UART 硬件在软件中表现为一组内存映射的控制寄存器。因为这些物理地址是 RISC-V 的硬件连接到的 UART 设备，所以 loads 和 stores 是在和设备硬件通信而不是 RAM。UART 映射地址起始于 0x10000000，即  <code>UART0</code> 。UART0 有许多的控制寄存器，每个都是一个字节。它们相对于 UART0 的偏移定义在  <code>kernel/uart.c 中</code> 。例如， <code>LSP</code>  寄存器包含的位表明输入的字符是否有软件正在等待读取输入的字符。这些字符可能通过  <code>RHR</code>  寄存器读取。每读一次，UART 硬件都会从内部的 FIFO 删除，并在 FIFO 为空时，清楚掉  <code>LSR</code>  上的  <code>read</code>  标志。UART 发送硬件在很大程度上独立于接受设备，如果软件写了一个字符到 THR，UART 会发送这个字节。</p>\n<p>xv6 的  <code>main</code>  函数调用  <code>consoleinit</code>  来初始化 UART 硬件。这个代码配置每当 UART 收到输入的字符时，产生一个接受中断，并在每次 UART 发送时产生一个发送完成的中断。</p>\n<p>xv6 的 shell 通过  <code>init.c</code>  打开的文件描述符从控制台读取。调用  <code>read</code>  系统调用到达 <code>consoleread</code> 。 <code>consoleread</code>  等待输入到达并缓存在 cons.buf 中，拷贝输入到用户空间，最后返回用户进程。如果用户没有输入完一整行，任何正在读取的程序都会在 sleep 系统调用中等待。</p>\n<p>当用户输入一个字符时，UART 硬件会让 RISC-V 产生一个中断，激活 xv6 的陷阱处理。陷阱处理调用  <code>devintr</code> ，这个函数会查看 RISC-V 的  <code>scause</code>  寄存器以识别这个中断来自外部设备。然后它请求硬件调用 PLIC 来告诉它是那个设备中断。如果是 UART， <code>devintr</code>  会调用  <code>uartintr</code>  进行处理。</p>\n<p><code>uartintr</code>  从 UART 硬件中读取一个字符，并交给  <code>consoleintr</code> 。 <code>uartintr</code>  并不等待输入，因为后续的输入会产生新的中断。 <code>consoleintr</code>  的工作是在  <code>cons.buf</code>  中收集输入的字符指导整行到达。 <code>consoleintr</code>  会对特殊的字符做特殊处理。当新的一行到达的时候， <code>consoleintr</code>  打开一个 唤醒一个等待的  <code>consoleread</code> 。</p>\n<p>被唤醒之后， <code>consoleread</code>  会发现  <code>cons.buf</code>  中一整行的内容，将它拷贝到用户空间并返回。</p>\n<h2 id=\"code-控制台输出\"><a class=\"anchor\" href=\"#code-控制台输出\">#</a> Code: 控制台输出</h2>\n<p>一个作用于控制台文件描述符的 <code>write</code>  系统调用最终会走到  <code>uartputc</code> 。设备驱动会为执行写入的进程维护一个输出缓冲区，这样就不需要等待 UART 完成输出。相反， <code>uartputc</code>   将每个字符缓存到缓冲区中，调用  <code>uartstart</code>  以启动设备传输并返回。 <code>uartputc</code>  唯一会等待的情况是缓冲区已满。</p>\n<p>UART 每次完成发送一个字节时，都会产生一个中断。 <code>uartintr</code>  调用  <code>uartstart</code> ， <code>uartstart</code>  会检查设备是不是真的完成了发送动作，并把下一个缓冲区中准备输出的字符交给设备。因此，如果一个进程向控制台写入多个字节，通常第一个字节是由  <code>uartputc</code>  调用的  <code>uartstart</code>  发送，剩下的字节是因为发送完成的中断 <code>uartintr</code>  调用  <code>uartstart</code>  来发送的。</p>\n<p>要注意的是，这里通过缓冲区和中断，将设备活动和进程活动进行了解耦。控制台驱动在没有进程等待读取的时候也能处理输入，后续的读取能看到这些输入。同样的，进程能够直接发送输出而不需要等待设备。这个解耦能允许进程和设备 IO 并发执行以提升性能，这在设备很慢或者需要立即回显的时候尤其重要。这个想法有时也被称为并行 IO。</p>\n<h2 id=\"驱动程序中的并发\"><a class=\"anchor\" href=\"#驱动程序中的并发\">#</a> 驱动程序中的并发</h2>\n<p>你可能注意到在  <code>consoleread</code>  和  <code>consoleintr</code>  中调用了  <code>acquire</code> 。这会持有一个锁，它保护并发访问的情况下控制台驱动的数据结构。这里有三个并发的威胁：两个不同 CPU 的进程同时调用  <code>consoleread</code> ；当 CPU 在  <code>consoleread</code>  中执行时，硬件可能要求 CPU 发送一个控制台中断；当正在执行  <code>consoleread</code>  时，硬件可能在其他 CPu 上产生一个控制台中断。第六章将探讨锁在这些场景下的应用。</p>\n<p>驱动中还需要关心的另一种并发情况是一个进程正在等待来自设备的输入，但是另一个进程的输入中断信号到达了。因此，中断处理不允许考虑他们中断的进程和代码。例如，一个中断处理不能安全的在当前进程页表上调用  <code>copyout</code> 。中断处理程序一般只做很少的工作，例如拷贝输入数据到缓冲区，剩下的工作将交由  <code>top-half</code>  来完成。</p>\n<h2 id=\"时钟中断\"><a class=\"anchor\" href=\"#时钟中断\">#</a> 时钟中断</h2>\n<p>xv6 使用时钟中断来维护它的时钟并驱动进程切换，这个模式被成为  <code>compute-bound</code> 。 <code>usertrap</code>  和  <code>kerneltrap</code>  调用  <code>yield</code>  来进行进程切换。时钟中断来自于每个 RISC-V CPU 的时钟硬件。xv6 将此时钟硬件编程为定期中断每个 CPU。</p>\n<p>RISC-V 要求时钟终端产生于机器模式（m-mode）而不是 s-mod。RISC-V 的 m-mod 工作时没有页表，并使用独立的控制寄存器，所以在 m-mod 运行 xv6 内核是不实际的。所以，xv6 的时钟中断完全独立于上述的陷阱机制。</p>\n<p>位于  <code>start.c</code>  中的代码就是在 m-mod 下执行的，在  <code>main</code>  函数之前就设置了时钟中断。这部分的工作是对 CLINT 进行编程以定时产生一个中断。并一部分是设置一块空的区域，就像 trapframe 一样，以协助时钟终端保存寄存器和 CLINT 寄存器的地址。最终， <code>start</code>  设置  <code>mtvec</code>  的值为  <code>timervec</code>  以启用时钟中断。</p>\n<p>时钟中断可以发生在用户或内核代码执行时；即使内核在进行一些关键操作的时候，也无法关闭时钟中断。因此，时钟中断的处理程序必须保证不打乱内核代码。一个基本的策略是中断处理程序让 RISC-V 生成一个软中断然后立刻返回。RISC-V 将这个软中断以常规陷阱的机制传递给内核，并允许内核禁用这些软中断。处理由时钟中断产生的软中断代码位于  <code>devintr</code> 。</p>\n<p>m-mod 模式的时钟中断处理程序是  <code>timervec</code> 。它保存很少的寄存器在  <code>start</code>  分配的空区域中，并告诉 CLINT 当产生下一个时钟中断的时候，让 RISC-V 产生一个软中断，恢复寄存器并返回。定时器中断处理程序没有 C 代码。</p>\n<h2 id=\"real-world\"><a class=\"anchor\" href=\"#real-world\">#</a> Real world</h2>\n<p>xv6 允许设备中断和时钟中断用户态和内核态发生。即使在内核态的时候，时钟中断强制让一个进程进行切换。这对内核花费大量的时间做计算，而不返回用户空间的公平时间分片很有用。然而，需要考虑，如果内核被挂起，然后在其他 CPU 上恢复，这是 xv6 中一切复杂性的根源。如果设备中断和时钟中断仅仅发生在用户态的话，内核将会简单一些。</p>\n<p>在一台计算机上全面支持所有设备是一项困难的工作，因为这会有很多设备，设备有很多特性，设备之间的协议可能很复杂。在许多操作系统上，设备驱动代码比核心内核代码还多。</p>\n<p>UART 设备通过读取 UART 的控制寄存器一次检索一个字符。这部分被叫做  <code>programmed I/O</code> 。因为软件正推动数据的移动。IO 编程是简单的，但在高频数据上会很慢。通常来说，设备需要使用 DMA （direct memory access）技术来移动大量的数据。DMA 设备直接将数据写道 RAM 中，并且从 RAM 读取数据。现代硬盘和网络设备都使用 DMA 技术。DMA 设备的驱动会在 RAM 中准备数据，并通过写一个控制寄存器来告诉硬件处理准备好的数据。</p>\n<p>当设备在不可预计的时间需要被系统注意时（但不会经常发生），中断就显得有意义了。但是中断具有很高的 CPU 开销。因此高速设备，例如网络和硬盘控制器会使用一些特殊的手段来减少中断。一种手段是对数据进行批量处理。另一种手段是完全禁用设备中断，并周期性的主动检测设备是否需要进行处理。这种方式被称为 <code>polling</code> 。 <code>polling</code>  在设备快速操作时是有意义的，但如果设备大多数时候都很空闲，就会浪费 CPU 轮询。一些设备会根据当前加载情况动态的切换  <code>polling</code>  还是中断。</p>\n<p>UART 设备拷贝第一个字符到内核中，然后把数据返回用户态。这在低速数据上是有意义的，但是这样双拷贝会降低性能。一些操作系统还会使用 DMA 来直接从设备中拷贝数据到用户空间。</p>\n<h2 id=\"练习\"><a class=\"anchor\" href=\"#练习\">#</a> 练习</h2>\n<ol>\n<li>修改  <code>uart.c</code>  不再使用中断。你可能需要同时修改  <code>console.c</code></li>\n<li>添加一个网卡驱动</li>\n</ol>\n",
            "tags": [
                "xv6",
                "xv6-book中文翻译"
            ]
        },
        {
            "id": "https://i.merore.com/xv6/xv6-book-translate/chapter-4-trap-and-system-call/",
            "url": "https://i.merore.com/xv6/xv6-book-translate/chapter-4-trap-and-system-call/",
            "title": "Chapter 4 陷阱和系统调用",
            "date_published": "2022-11-03T02:38:38.000Z",
            "content_html": "<h1 id=\"chapter-4-陷阱和系统调用\"><a class=\"anchor\" href=\"#chapter-4-陷阱和系统调用\">#</a> Chapter 4 陷阱和系统调用</h1>\n<p>有三种事件会让 CPU 搁置正常的指令执行流并强制将控制转移到处理该事件的特殊代码。一种情况是 <code>系统调用</code> ，当一个用户程序执行  <code>ecall</code>  指令请求内核做一些事情。另一种情况是 <code>例外</code> ：一个指令做了一些不合法的，例如除以 0，或者使用无效的虚拟地址。第三种情况是 <code>设备中断</code> ，当一个设备信号发出需要注意的信号，例如当硬盘完成了一次读或者写请求。</p>\n<p>本书使用  <code>陷阱（trap）</code>  作为这些通用情况的术语。通常来说，当代码在执行时发生陷阱后进行恢复时，并且不需要知道发生了什么。所以，我们经常希望陷阱是透明的。这对中断来说尤其重要，这是被中断代码通常不期望的。通常的流程是陷阱将控制权转给内核；内核保存寄存器和其他状态以让执行能够恢复；内核执行合适的处理代码；内核回复保存的状态并从陷阱中恢复；原来的代码从离开的地方恢复。</p>\n<p>xv6 内核处理了所有的 陷阱。这对系统调用来说是很自然的。这对中断来说是有意义的，因为隔离性要求用户程序不直接使用设备，且只有内核拥有设备处理需要的状态。这对例外来说也是有意义的，因为 xv6 对所有的例外响应都是杀死对应的程序。</p>\n<p>xv6 对陷阱的处理有四个阶段：RISC-V cpu 采用硬件操作，一个为内核准备的 C 代码。一个 C 陷阱处理代码决定如何处理这个陷阱，是系统调用还是设备驱动服务。虽然三种陷阱的共性表明可以用一个代码进行处理，事实上对三种情况处理更方便，来自用户空间的陷阱，来自内核空间的陷阱，时钟中断。</p>\n<h2 id=\"risc-v-陷阱机制\"><a class=\"anchor\" href=\"#risc-v-陷阱机制\">#</a> RISC-V 陷阱机制</h2>\n<p>每个 RISC-V CPU 有一组内核可写的控制寄存器以告诉 CPU 如何处理陷阱，同时内核可以读这些寄存器以理解到发生了什么陷阱。RISC-V 的文档有这些全部的定义。riscv.h 包含了 xv6 使用的定义。这有一份大纲包含重要的寄存器。</p>\n<ul>\n<li><code>stvec</code> ：内核将陷阱处理代码的地址写在这里；RISC-V 跳转到这里以处理陷阱。</li>\n<li><code>sepc</code> ：当陷阱发生的时候，RISC-V 将程序计数器保存在这里，因为 pc 会被 stvec 重写。 <code>sret</code>  指令会拷贝 sepc 到 pc 中，内和可以写 sepc 来控制 sret 的目标地址。</li>\n<li><code>scause</code> ：  RISC-V 放一个数字在这里，描述陷阱发生的原因。</li>\n<li><code>sscratch</code> ： 内核在这里放置一个值，在陷阱开始处理之前使用。（所以到底是干啥的）</li>\n<li><code>sstatus</code> ： 这个寄存器的 SIE 比特位控制哪个设备终端被允许。如果内核清除了 SIE，RISC-V 将会推迟设备终端，直到内核重新设置 SIE。SPP 比特位表明这些陷阱来自用户模式还是监督者模式，并且控制 sret 返回到哪个模式。</li>\n</ul>\n<p>上述寄存器是在 s-mod 中处理陷阱使用的，它们不能在用户模式下读写。还有一组等效的控制寄存器用于 m-mod；xv6 仅将他们用于定时器中断这个特殊情况。</p>\n<p>多核上的每个 CPU 都有自己的寄存器，并且可能会有很多 CPU 同时处理陷阱。</p>\n<p>当需要强制进入陷阱时，RISC-V 硬件会进行以下步骤（除了时钟中断）</p>\n<ol>\n<li>如果是设备中断，并且 sstatus 的 SIE 位被清除，不做任何操作</li>\n<li>清除 SIE ，以关中断</li>\n<li>将 pc 值复制到 spec</li>\n<li>在 sstatus 的 SPP 位上保存当前模式</li>\n<li>设置 scause 保存陷阱原因</li>\n<li>设置为 s-mod</li>\n<li>将 pc 值设置为 stvec 的值（这个 stvec 的值是谁设置的）</li>\n<li>在 新的 pc 处开始执行</li>\n</ol>\n<p>注意，CPU 并不切换内和页表，不切换内核栈，不保存除了 pc 以外的寄存器值。内核必须执行这些内容。CPU 在陷阱期间做少量工作的原因是给系统提供灵活性。例如，一些操作系统在某些情况下不需要页表，这能提升性能。</p>\n<p>你可能想知道 CPU 硬件陷阱处理是否还能进一步简化。例如，认为 CPU 不需要切换程序计数器。然后陷阱能切换到 s-mod 当在运行用户指令时。这些用户指令会破坏用户内核的隔离性，例如通过修改 satp 寄存器指向页表以访问所有的物理内存。因此，CPU 切换到内核指定地址很重要。</p>\n<h2 id=\"用户空间陷阱\"><a class=\"anchor\" href=\"#用户空间陷阱\">#</a> 用户空间陷阱</h2>\n<p>在用户空间，陷阱会发生在执行系统调用，或者做一些非法操作，或者如果设备中断。来自最高级的用户陷阱是  <code>uservec（kernel/trampoline.S）</code> ，然后是  <code>usertrap(kernel/trap.c)</code>  然后是返回  <code>usertrapret(kernel/trap.c)</code>  然后是  <code>userret(kernel/trampoline.S)</code> 。</p>\n<p>来自用户代码的陷阱比内核更具有挑战性，因为 satp 指向的用户页表没有内核地址的映射，并且对战指针可能包含无效的或者恶意的值。</p>\n<p>因为 RISC-V 硬件在中断期间不切换页表，用户页表必须包含  <code>uservec</code>  的映射。而 <code>uservec</code>  必须 切换  <code>satp</code>  到内核页表上。为了在切换后继续执行指令， <code>uservec</code>  必须在内核页表中映射用户页表相同的地址。这个虚拟地址就是  <code>TRAMPOLINE</code> 。这段代码的内容就是  <code>trampoline.S</code>  。 <code>stvec</code>  将会被设置为  <code>uservec</code> 。</p>\n<p>当  <code>uservec</code>  启动的时候，所有的 32 个寄存器都包含着中断代码所用的值。但是  <code>uservec</code>  需要能够修改一些寄存器的值，以设置 satp，并且生成保存寄存器的地址。 RISC-V 提供了一个  <code>sscratch</code>  寄存器协助完成这个事情。 <code>csrrw</code>  指令一开始交换  <code>a0</code>  和  <code>sscratch</code> 。现在，用户代码的  <code>a0</code>  被保存了。 <code>uservec</code>  就有了一个  <code>a0</code>  寄存器使用。这个  <code>a0</code>  就是内核先前放在  <code>sscratch</code>  中的值。</p>\n<p><code>uservec</code>  的下一个任务是保存用户寄存器。在进入用户空间之前，内核提前设置了  <code>sscratch</code>  来指向没一个进程的  <code>trapframe</code>  。这个 陷阱帧保存用于保存所有的用户寄存器。因为  <code>satp</code>  指向用户页表， <code>uservec</code>  需要在用户空间映射。在 xv6 创建没一个线程时，xv6 分配一个页，用于进程的陷阱帧，并且将其映射到虚拟地址  <code>TRAPFRAME</code> ，这在  <code>TRAMPOLINE</code>  下。进程的  <code>p-&gt;trapframe</code>  指向的是物理地址，这样内核可以直接使用。</p>\n<p>因此在交换  <code>a0</code>  和  <code>sscratch</code>  后， <code>a0</code>  指向当前进程的 <code>trapframe</code> 。 <code>uservec</code>  保存了所有的用户寄存器，包括 a0。</p>\n<p><code>trapframe</code>  包含当前进程的内核栈，当前 cpu 的 id。 <code>usertrap</code>  的地址。内核页表的地址。 <code>uservec</code>  会检索这些值，切换 satp 到内核页表，然后调用  <code>usertrap</code> 。</p>\n<p><code>usertrap</code>  的工作是检测陷阱的原因，处理，并返回。就像上边提到的，首先修改  <code>stvec</code>  以让  <code>kernelvec</code>  能处理这个陷阱。再次保存  <code>spec</code>  的值，因为可能因为程序切换  <code>usertrap</code>  重写  <code>sepc</code>  。如果这个陷阱是系统调用， <code>syscall</code>  处理。如果是设备中断 <code>devintr</code> 。不然就是一个例外，内核会杀死这个错误的程序。如果是系统调用的话，会将保存的  <code>pc</code>  值加上 4，因为系统调用会让程序指针指向  <code>ecall</code>  指令。在返回时， <code>usertrap</code>  会检查程序是否被杀死或应该让出 cpu（时钟中断）。</p>\n<p>返回用户空间第一步是调用  <code>usertrapret</code> 。这个函数会设置 RISC-V 的控制寄存器，为后来的用户空间陷阱做准备。这会让  <code>stvec</code>  指向  <code>uservec</code> ，准备 trapframe 的字段，将  <code>sepc</code>  设置为保存的程序计数器的值。最后， <code>usertrapret</code>  调用在内核和用户都有映射的  <code>userret</code> 。因为  <code>userret</code>  将会切换页表。</p>\n<p><code>usertrapret</code>  调用  <code>userret</code>  通过在 a0 中传递程序的用户页表，a1 传递 TRAPFRAME。 <code>userret</code>  切换  <code>satp</code>  到进程用户页表。 <code>userret</code>  拷贝 trapframe 保存的用户 a0 到 sscratch 中，以在 TRAPFRAME 中交换。从这一点来说， <code>userret</code>  能够使用的数据是寄存器和陷阱中的内容。接下来， <code>userret</code>  从 trapframe 中恢复保存的用户寄存器。最终交换 a0 和 sscratch 以回复用户 a0 并为下一次陷阱保存 TRAPFRAME。最后使用  <code>sret</code>  返回用户空间。</p>\n<h2 id=\"code-进行系统调用\"><a class=\"anchor\" href=\"#code-进行系统调用\">#</a> Code: 进行系统调用</h2>\n<p>第二章在  <code>initcode.S</code>  调用  <code>exec</code>  系统调用结束。让我们看看内核是如何实现用户调用  <code>exec</code>  系统调用的。</p>\n<p>用户代码将参数放在 a0,a1 中传递给 exec。并将系统调用号放在 a7 中。系统调用匹配  <code>syscalls</code>  数组。 <code>ecall</code>  指令陷入内核，并执行  <code>uservec，usertrap</code>  最后执行  <code>syscall</code> 。（这里讲的有点混乱，匹配 syscalls 是在处理中断之后才做的。而且第一次 initcode 从内核返回用户态也没讲到。）</p>\n<p><code>syscall</code>  检索 trapframe 中存储的 a7 值，对于第一个系统调用，a7 包含  <code>SYS_exec</code> ，调用系统实现函数  <code>sys_exec</code> 。</p>\n<p>当系统调用实现返回时， <code>syscall</code>  记录返回值在 p-&gt;trapframe-&gt;a0 中。用户的 exec () 将会返回这个值，因为 RISC-V 的 c 函数调用约定使用  <code>a0</code>  作为返回值。系统调用约定返回负值表示错误。零 或者 正数表示成功。如果系统调用号不合法，返回 -1。</p>\n<h2 id=\"系统调用参数\"><a class=\"anchor\" href=\"#系统调用参数\">#</a> 系统调用参数</h2>\n<p>内核中的系统调用实现需要找到用户传递的参数。因为用户使用函数封装调用，参数根据 RISC-V 的 c 函数调用的原则放在寄存器中。内核陷阱代码保存用户寄存器到进程的陷阱帧中，内核代码能够找到这些值。函数  <code>argint，argaddr</code>  和  <code>argfd</code>  在陷阱帧中检索第 n 个系统调用参数，这些参数是整数，指针，或者文件描述符。他们都会调用  <code>argraw</code>  来检索用户寄存器保存的值。</p>\n<p>一些系统调用传递指针作为参数，内核必须使用这些指针来读写用户的内存。例如  <code>exec</code>  系统调用，传递一个指向参数的指针数组。这些指针提出了两个挑战。首先，用户程序可能是有害的，可能给内核传递一个非法指针或者这个指针欺骗内核访问内核地址空间而不是用户地址空间。其次，xv6 内核页表并没有映射用户页表，所以内核不能使用普通的指令从用户地址读写。</p>\n<p>内核实现了安全的函数传递数据。fetchstr 是一个例子。文件系统调用例如  <code>exec</code>  使用  <code>fetchstr</code>  检索来自用户空间的文件名。 <code>fetchstr</code>  调用  <code>copyinstr</code>  来完成这个工作。</p>\n<p><code>copyinstr</code>  拷贝从  <code>srcva</code>  开始的最多  <code>max</code>  个字节。它使用  <code>walkaddr</code>  函数以在页表上找到  <code>srcva</code>  对应的物理地址  <code>pa0</code> 。因为内核直接映射了所有的物理地址， <code>copyinstr</code>  能够直接从  <code>pa0</code>  拷贝字符串到  <code>dst</code> 。 <code>walkaddr</code>  检查用户提供的虚拟地址是用户地址空间的一部分。所以程序不能误导内核读取其他内存。还有一个很相似的函数  <code>copyout</code> ，从内核拷贝数据到用户提供的地址。</p>\n<h2 id=\"来自内核的陷阱\"><a class=\"anchor\" href=\"#来自内核的陷阱\">#</a> 来自内核的陷阱</h2>\n<p>xv6 根据是否用户或内核代码正在执行，配置 CPU 陷阱寄存器有些不同。当 CPU 在执行内核代码时，内核  <code>stvec</code>  指向  <code>kernelvec</code> 。因为 xv6 已经在内核中， <code>kernelvec</code>  的  <code>satp</code>  已经指向内核页表，以及指向有效内核栈的栈指针。 <code>kernelvec</code>  保存所有的寄存器以从中断中恢复。</p>\n<p><code>kernelvec</code>  将寄存器保存在陷入中断的内核线程栈上，这是有意义的，因为这些寄存器属于该线程。这对那些造成线程切换的陷阱来说尤其重要，因为陷阱将会返回到一个新的线程上，被保存的寄存器值仍然安全的在其自己的栈上。</p>\n<p>在保存寄存器后， <code>kernelvec</code>  跳转到  <code>kerneltrap</code> 。 <code>kerneltrap</code>  有两种类型的陷阱：设备中断和例外。调用  <code>devintr</code>  来处理设备中断。如过陷阱不是设备终端，就是一个例外，这在 xv6 里会始终造成一个致命错误。内核将调用  <code>panic</code>  并停止执行。</p>\n<p>如果  <code>kerneltrap</code>  是由于时钟中断造成的，并且一个进程的内核线程正在执行（不是调度线程）， <code>kerneltrap</code>  调用  <code>yield</code>  以让出 cpu 来让其他线程选择运行。在某一时刻，其他的某个线程也会执行  <code>yield</code> ，来让我们的线程和  <code>kerneltrap</code>  再次运行。第七章将会解释  <code>yeild</code>  发生了什么。</p>\n<p>当  <code>kerneltrap</code>  完成时，它需要返回被中断的代码。由于  <code>yield</code>  可能造成 sepc 和 保存的 sstatus 改变， <code>kerneltrap</code>  在开始时保存了它们，现在，恢复这些控制寄存器并返回到  <code>kernelvec</code>  中。 <code>kernelvec</code>  弹出保存在栈上的寄存器，并执行  <code>sret</code> 。这会拷贝  <code>sepc</code>  的值到  <code>pc</code>  并从中断的内核代码恢复。</p>\n<p>值得思考的是， <code>kerneltrap</code>  由于时钟中断调用  <code>yield</code>  时陷阱最终是如何返回的。</p>\n<p>当 CPU 从用户态进入内核态时，xv6 设置 CPU 的  <code>stvec</code>  为  <code>kernelvec</code> 。当内核开始执行到设置  <code>stvec</code>  设置  <code>uservec</code>  有一个时间窗口，在该期间禁用设备中断相当重要。幸运的是，RISC-V 总是在 trap 期间禁用中断，并且 xv6 在设置  <code>stvec</code>  之前都不允许启用中断。</p>\n<h2 id=\"页表例外\"><a class=\"anchor\" href=\"#页表例外\">#</a> 页表例外</h2>\n<p>xv6 对于例外的响应相当无聊，如果例外发生在用户空间，内核将杀死这个错误的进程。如果例外发生在内核，内核会 panic。真实的操作系统在响应例外时会有很多有趣的方式。</p>\n<p>例如，许多内核使用页表错误实现  <code>copy-on-write (COW) fork</code> 。为了解释  <code>copy-on-write</code>  fork，参考 xv6 的  <code>fork</code> 。 <code>fork</code>  会造成子进程拥有和父进程同样的内存内容，通过调用  <code>uvmcopy</code>  分配物理内存并将父进程的内容拷贝给子进程。如果父进程和子进程共享物理内存，效率会更高。然而，一个直接的实现是行不通的，因为这会造成父子进程在各自堆栈进行读写时混乱。</p>\n<p>父子进程可以  <code>copy-on-write fork</code>  安全的共享物理内存，这一技术通过  <code>page fault</code> 。当一个 CPU 不能将虚拟地址翻译为物理地址时，CPU 生车一个  <code>page-fault 例外</code> 。RISC-V 有是那种不同类型的页错误： <code>load page faults</code>  当加载指令不能翻译它的虚拟地址时， <code>store page fault</code>  当存储指令不能翻译它的虚拟地址时。 <code>instruction page faults</code>  当地址上的指令不能执行的时候。 <code>scause</code>  寄存器的值将会标识是哪种  <code>page fault</code>  并且  <code>stval</code>  寄存器包含了不能翻译的地址。</p>\n<p>COW fork 的基本方案是父子进程最初共享所有的物理页，但将他们均映射为 read-only。因此，当父进程或子进程执行存储指令时，RISC-V CPU 发生一个 page-fault 例外。为了响应这个例外，内核生成一个包含该地址的页的拷贝。将这个页映射为读写到子进程的地址空间，另一个拷贝映射为读写到父进程地址空间。更新 u 页表后，内核重新执行造成此多无的进程。由于内核已经更新的关联的 PTE ，这次执行将不会再有这个错误。（译者注：这里的意思是，因为父子进程指向同样的物理地址空间，他们可以读，但并不能同时写，所以在写的时候，将他们指向不同的物理地址，这样就能分开了。但是译者认为。这样的做法比在 fork 时完整复制物理页表显得不够干净，将这种缺页错误分散在了程序运行的各个时段，并且每次陷入内核开销更大）</p>\n<p>这个  <code>COW</code>  方案对  <code>fork</code>  来说是 ok 的，因为子进程经常在调用  <code>fork</code>  后调用  <code>exec</code> ，用新的地址空间替换原来的地址空间。这样的话，子进程将只会发生少量的 page-fault，并且内核能够避免完全拷贝。进一步来说，COW 是透明的，对应用程序来说不需要做任何修改即可使用。</p>\n<p>页表和页错误的组合开辟了除 COW 以外的有趣可能。另一个被广泛使用的特性叫做 <code>lazy allocation</code> ，这包括两部分，首先，当一个程序掉哟个你 sbrk 时，内核增长其地址空间，但是将新的地址标记为 invalid。第二，当页错误发生在这个新地址上时，内核分配物理内存并将其映射到页表上。由于应用程序进程请求比他们需要的更多的内存，懒分配就有了优势，内核仅仅在应用程序实际使用的时候才为他们分配内存。和 COW 一样， 内核也能将其实现为对应用程序透明。</p>\n<p>另一个广泛使用利用 page-fault 的是  <code>paging from disk</code> 。如果一个应用程序需要的内存比物理内存还多，内核可以驱逐一些页，将他们写入硬盘并将他们的 PTEs 标志为 invalid。如果一些应用程序读或写驱逐页，CPU 会遇到页错误。内核能够检查错误的地址，从磁盘中读出内存内容到内存中，更新 PTE 为 valid 并指向内存，然后继续运行应用程序。为了给这个页腾出空间，内核可能需要取出其他的页。这个特性需要对应用程序无修改。</p>\n<p>其他结合页表和页错误的特性还包括自动扩展栈和内存映射文件。</p>\n<h2 id=\"real-world\"><a class=\"anchor\" href=\"#real-world\">#</a> Real world</h2>\n<p>如果将整个内核内存映射到每个进程的用户页表，就可以不再使用特殊的  <code>trampoline page</code> 。从用户到内核是也不再需要切换页表。反过来，内核中的有了用户地址，也能直接解引用用户指针。许多操作系统使用这个想法提高效率。xv6 避免使用的原因是因为减少直接使用用户指针可能存在的安全问题，和减少内核虚拟地址和用户虚拟地址不重叠的复杂性。</p>\n<h2 id=\"练习\"><a class=\"anchor\" href=\"#练习\">#</a> 练习</h2>\n<ol>\n<li><code>copyin</code>  和  <code>copyinstr</code>  以软件的形式遍历页表。调整内核页表以有用户程序的映射，让  <code>copyin</code>  和  <code>copystr</code>  能够直接使用  <code>memcpy</code>  拷贝系统调用参数到内核空间，以硬件的方式。</li>\n<li>实现  <code>lazy allocation</code></li>\n<li>实现  <code>cow fork</code></li>\n</ol>\n",
            "tags": [
                "xv6",
                "xv6-book中文翻译"
            ]
        },
        {
            "id": "https://i.merore.com/xv6/xv6-book-translate/chapter-3-pagetable/",
            "url": "https://i.merore.com/xv6/xv6-book-translate/chapter-3-pagetable/",
            "title": "Chapter 3 页表",
            "date_published": "2022-11-03T01:43:18.000Z",
            "content_html": "<h1 id=\"chapter-3-页表\"><a class=\"anchor\" href=\"#chapter-3-页表\">#</a> Chapter 3 页表</h1>\n<p>页表是操作系统给每个进程提供私有地址空间和内存的一种机制。页表决定内存地址的意义以及哪些物理内存能够访问。他们允许 xv6 在同一块物理内存上隔离不同进程的地址空间。页表还间接的为 xv6 提供了一些手段：在多个地址空间中映射相同的内存地址，通过未分配的页来保护内核和用户栈。本章其余章节介绍 RICS-V 硬件提供的页表机制以及 xv6 将如何使用他们。</p>\n<h2 id=\"页表硬件\"><a class=\"anchor\" href=\"#页表硬件\">#</a> 页表硬件</h2>\n<p>提醒一下，RISC-V 指令集（包括用户和内核）操作的都是虚拟地址。机器 RAM，或者说是物理内存，是由物理地址进行索引。RISC-V 页表硬件通过映射虚拟地址到物理地址来连接这两种类型的地址。</p>\n<p>xv6 运行在 Sv39 RISC-V 上，这意味着 64 位虚拟地址中只有低 39 位地址被使用。高 25 位没有被使用。在 Sv39 中，一个 RISC-V <code> 页表页（page-table page）</code> 是一个 2^27   <code>页表块（PTE）</code>  的数组。每个 PTE 包含一个 44 位的物理地址和 10 位标志。物理页表使用 39 位中的高 27 位在页表中找到 PTE，并且标志一个 56 位物理地址，物理地址的高 44 位来自 PTE 中的地址，低 12 位则直接从虚拟地址拷贝作为页内偏移。如图展示了单一页表示意图（每一个页表本身占用 512 * 8 个连续字节的物理内存，刚好也是一个物理页的大小 4096 字节）。页表让操作系统以 4096 字节大小为单位控制物理内存。这个单位被称作  <code>page （页）</code> 。<br />\n<img data-src=\"https://s2.loli.net/2022/11/03/EaSIsdWqmJVfQGF.png\" alt=\"22834193-dad9da811179de3e.png\" /></p>\n<p>在 Sv39 RISC-V 中，高 25 位虚拟地址没有用于翻译，未来 RISC-V 可能会使用这些位来定义更多等级的翻译。物理地址也有增长空间，因为 PTE 中还剩下 10 个比特位可用于扩展。</p>\n<p>如图 3.2 所示，实际的页表翻译有三个步骤。一个完整的页表是作为一个三级树存储在物理内存中的。树的根是一个 4096 字节的页表页，包含 512 个 PTEs（每个 PTE 占 8 字节，也就是 64 位，但仅使用低 55 位），这些 PTES 由两个部分组成，高 44 位保存的内容指向下一级页表页的物理地址，低 10 位是页表的一些标识位。对每一个虚拟地址来说，首先根据虚拟地址 27 位中的 高 9 位，来确定一个 0～512 之间的值，这个值表示一级页表中 PTE 的位置。然后便能根据这个 PTE，确定下一个页表页的位置。同理，中间的 9 位标识 第二级页表 PTE。最终我们可以得到第三级 PTE。<br />\n<img data-src=\"https://s2.loli.net/2022/11/03/wZK2nHPfl9ForpI.png\" alt=\"22834193-d2d202f6da9bd8d7.png\" /></p>\n<p>当在进行三级页表查找转换时，如果任意一个地址对应的页表不存在导致地址无法翻译，硬件将会产生一个  <code>page-fault exception（页错误例外）</code> ，并将这个例外交给内核处理。这种三级结构允许页表在虚拟地址大部分都未进行映射的情况下，直接省略整张页表，以节省页表页本身的内存开销。</p>\n<p>每个 PTE 包含 flag 标志位以告诉硬件被关联的虚拟地址是否允许被使用。PTE_V 表示当前 PTE 是否存在（有效）；如果没有设置该标志位，任何指向该页的引用会造成例外。PTE_R 控制是否允许指令读取该页内容。PTE_W 控制是否允许指令写该页。PTE_X 控制是否是否允许 CPU 解释页的内容并执行。PTE_U 控制是否允许 user mode 访问该页；如果 PTE_U 没有设置，PTE 只能被 supervisor mode 使用。图 3.2 展示了这是如何工作的。其他标志位和其他页表硬件结构被定义在 kernel/riscv.h。（译者注：值得一提的是，在 xv6 中，仅有最后一级指向物理地址的 PTE 标志位会设置 RXWU 等。指向下一级页表页的 PTE，其标志位仅有 PTE_V，此特征在 xv6 中用于判断 PTE 是否是最后一级 PTE)。</p>\n<p>为了让硬件能使用页表，内核必须将 root 页表页（也就是第一级页表页）的地址写入 satp 寄存器。每个 CPU 有自己的 satp 寄存器。每个 CPU 都会使用他自己的 satp 寄存器来翻译随后的指令以及指令中的地址。每个 CPU 有自己的 satp 才能让不同的 CPU 运行不同的进程，因为每个进程都有自己独有的以页表映射的私有地址空间。</p>\n<p>一些术语。物理内存指的是 DRAM 中的存储单元。一个字节的物理内存有一个地址，叫做物理地址。指令只能使用虚拟地址，由页表硬件翻译成物理地址，然后发给 DRAM 硬件进行读写。与 <code>物理内存</code> ， <code>虚拟地址</code> 不同的是， <code>虚拟内存</code> 不是实际的物理含义，而是内核提供的一种管理物理内存和虚拟地址的机制手段。</p>\n<h2 id=\"内核地址空间\"><a class=\"anchor\" href=\"#内核地址空间\">#</a> 内核地址空间</h2>\n<p>xv6 为每个进程维护一个页表，描述每个进程的用户地址空间，加上一个独立的描述内核地址空间的页表。内核配置地址空间布局以让其能够可预测的访问物理内存和其他硬件资源。下图是 xv6 内核内存布局。<br />\n<img data-src=\"https://s2.loli.net/2022/11/03/ENy5kWPlT7jp2Zb.png\" alt=\"22834193-859410fff007d444.png\" /></p>\n<p>QEMU 模拟的电脑，其物理内存起始地址为 0x80000000 至少终止于 0x86400000 ，这在 xv6 中叫做 PHYSTOP。QEMU 模拟器还包括 I/O 设备例如硬盘接口。QEMU 通过映射他们到 0x8000000 地址以下来暴露这些接口。内核可以通过读写这些特殊的物理地址来与设备交互。这是与物理设备交互而不是 RAM。第四章解释了 xv6 是如何与物理设备交互的。</p>\n<p>内核使用直接映射的方式获取 RAM 和 内存设备映射。也就是说，映射资源的虚拟地址和物理地址是一致的。在内核内存布局中，左边是 xv6 的内核地址空间，RWX 表示这个 PTE 读写执行权限。右边是 risc-v 期望看见的物理地址空间。</p>\n<p>内核在虚拟地址和物理地址上都位于  <code>KERNBASE=0x80000000</code> 。直接映射简化内核代码读写物理内存。例如，当 fork 为子进程分配用户内存时，分配器返回内存的物理地址；当拷贝父进程的用户内存时，fork 直接将这个地址作为虚拟地址使用。有一些内核的地址不是直接映射的：</p>\n<ul>\n<li>Trampoline Page: 被映射在虚拟地址的高位；用户页表也有同样的映射。第四章将讨论 Trampoline Page，但我们能在这里看到一个页表的一个有趣的使用；一个包含 Trampoline Code 的物理页被映射到虚拟地址两次，一次在虚拟地址顶部一次直接映射。</li>\n<li>内核栈页：每个进程都它自己的被映射在高位的内核栈， xv6 还在栈下留下未映射的  <code>guard page 保护页</code> 。保护页的 PTE 是无效的（PTE_V 未设置），这样如果内核溢出到内核栈，将会引起例外内核会崩溃。如果没有保护页，栈溢出将覆盖其他的内核内存区域，造成错误的操作。这样的异常崩溃是良性的。</li>\n</ul>\n<p>虽然内核使用高地址映射堆栈，但内核也可以通过直接映射地址访问他们。另一种设计只有直接映射并用直接映射使用。但那样的话，提供保护页必须不再映射虚拟地址，否则这些地址对应的的物理地址不太方便使用。</p>\n<p>内核为  <code>Trampoline</code>  和  <code>Kernel Text</code>  以 TPE_R 和 PTE_X 的权限进行映射。内核从这些页里读取并执行指令。内核以 PTE_R 和 PTE_W 的权限映射其他页，这样能够在这些页内进行读写。对保护页的映射是不允许的。</p>\n<h2 id=\"code-创建一个地址空间\"><a class=\"anchor\" href=\"#code-创建一个地址空间\">#</a> Code: 创建一个地址空间</h2>\n<p>大多数操作地址空间和页表的代码分布在  <code>vm.c （kernel/vm.c）</code>  文件中。 核心数据结构  <code>pagetable_t</code> ，是一个指向 RISC_V 根页表页的指针；一个 pagetable_t 要么是一个内核页表，要么是一个进程页表。核心函数是  <code>walk</code> ，它为虚拟地址查找 PTE 和 mappages，mappage 用于创建新的虚拟地址到物理地址的映射。以 kvm 开头的函数操作内核页表。以 uvm 开头的函数操作用户页表。其他函数用于这两者。  <code>copyout</code>  和  <code>copyin</code>  用于拷贝来自用户地址的数据。这两个函数位于  <code>vm.c</code>  中因为它们需要进行地址翻译以找到对应的物理地址。</p>\n<p>在早期的启动流程中，  <code>main</code>  调用  <code>kvminit</code>  创建内核页表。这个调用发生在 xv6 在 RISC-V 上启用页表之前，此时所有地址是直接指向物理内存的。 <code>kvminit</code>  首先分配一页物理内存来装载根页表页。然后调用 kvmmap 映射内核需要的翻译内容，这些内容包括内核指令和数据，物理内存到 PHYSTOP 和设备内存分布。</p>\n<p><code>kvmmap</code>  调用  <code>mappages</code>  将虚拟地址范围和物理地址范围的映射安装到页表中。它以页为单位，对每一页进行映射。对于每个被映射的虚拟地址， <code>mappages</code>  调用  <code>walk</code>  查找他的 PTE 地址。然后初始化 PTE 来装载物理页表地址，以及一些权限来标志 PTE 可用。</p>\n<p>walk 行为类似 RISC-V 页表硬件因为它查找一个虚拟地址的 PTE。walk 在 3 级也表中一次步进 9 位。它使用每一级的 9 位虚拟地址来查找下一级或者最后页的 PTE。如果 PTE 是无效的，表示需要的页还没有分配。如果设置了 alloc 参数，walk 分配一个新的页表页并将其物理地址写入 PTE。它返回树中最底层的 PTE 的地址。</p>\n<p>以上代码依赖物理内存直接映射到内核虚拟地址空间。例如当 walk 步进页表时，从 PTE 中获取下一级的物理地址，然后将其作为虚拟地址获取下一级 PTE 的虚拟地址。</p>\n<p><code>main</code>  调用  <code>kvminithart(kernel/vm.c)</code>  安装内核页表。它将物理根页表的物理地址写入  <code>satp</code>  寄存器。后续 CPU 会使用内核页表进行地址翻译。由于内核使用个直接映射，下一条指令的虚拟地址将会被正确的映射到物理地址上。</p>\n<p><code>procinit(kernel/proc.c)</code>  是被  <code>main</code>  函数调用的，为每一个进程分配内核栈。它将每个内核栈映射到由 KSTACK 生成的虚拟地址上，并为无效的堆栈保护页留下空间。 <code>kvmmap</code>  将映射的 PTEs 添加到内核页表，然后调用  <code>kvminithart</code>  重新装载内核页表到  <code>satp</code> ，这样硬件就知道了新的 PTEs。</p>\n<p>每个 RISC-V CPU 缓存页表块在  <code>Translation Look-aside Buffer (TLB)</code>  中，当 xv6 修改了页表时，必须告诉 CPU 以使相应的 TLB 缓存失效。如果不那么做的话，后续 TLB 可能会使用旧的缓存映射，同时指向贝其他进程分配的地址，结果，一个进程污染另一个进程的内存。RISC-V 有  <code>sfence.vma</code>  指令刷新 CPU 的 TLB 表。当重新加载  <code>satp</code>  后，xv6 在  <code>kvminithart</code>  中调用  <code>sfence.vma </code>  指令，在返回用户空间之前切换用户页表时也调用该指令。</p>\n<h2 id=\"物理内存分配\"><a class=\"anchor\" href=\"#物理内存分配\">#</a> 物理内存分配</h2>\n<p>内核必须在运行期间为页表，用户内存，内核栈和管道缓冲区分配和释放物理内存。<br />\nxv6 使用内核代码结束地址和 PHYSTOP 区域用于运行时分配。每次分配整个 4096 字节的页。通过一个列表标识哪些页面是空闲的，分配就从这个列表中移除这个页面，释放就将该页面添加到页表。</p>\n<h2 id=\"code物理内存分配\"><a class=\"anchor\" href=\"#code物理内存分配\">#</a> Code：物理内存分配</h2>\n<p>分配器代码位于  <code>kalloc.c(kernel/kalloc.c:1)</code> 。分配器的数据结构是一个可用与分配的物理页列表。每个空闲页列表的元素是一个 <code>struct run</code> 。分配器从哪里获得存取数据结构的内存？它将每个页的  <code>run</code>  结构存在空闲页本身中，因为这没有其他需要存的东西。空闲列表由 spin lock 保护。这个列表和锁被包装在一个结构体里以表示锁保护结构提内的字段。现在，忽略锁的细节，第六章将会解释。</p>\n<p><code>main</code>  函数调用  <code>kinit</code>  初始化分配器。 <code>kinit</code>  初始化空闲列以保存内核末尾和 PHYSTOP 之间的每一页。xv6 应该通过硬件提供的配置信息决定有多少物理内存可用。否则 xv6 认为机器有 128 MB 的 RAM。 <code>kinit</code>  调用  <code>freerange</code>  添加内存到空闲列表。一个 PTE 仅能指向 4096 字节对其的物理地址，所以  <code>freerange</code>  使用  <code>PGROUNDUP</code>  确保空闲列表是物理对齐的。分配器一开始没有内存，调用  <code>kfree</code>  进行物理内存初始化，并将内存交给它进行管理。</p>\n<p>分配器有时将地址视为整数以便进行数学运算（例如在  <code>freerange</code>  里遍历所有页），有时将地址用作指针以进行读写内存（例如操作在每个存储 run 结构的页）；这两种使用是分配器代码有大量 c 类型转换的原因。另一种原因是释放和分配改变了内存类型。</p>\n<p><code>kfree</code>  函数将释放的每个字节都置为 1。这样使用释放后内存的代码读取到的是无效数据而不是旧的信息，希望这能让这些代码更快的中断。然后  <code>kfree</code>  将该页作为表头前置，其具体步骤是，将  <code>pa</code>  转换成一个  <code>struct run</code>  结构体，将  <code>r-&gt;next</code>  指向旧表头，并将 r.kalloc 设置为空闲列表并返回列表的第一个元素。</p>\n<h2 id=\"进程地址空间\"><a class=\"anchor\" href=\"#进程地址空间\">#</a> 进程地址空间</h2>\n<p>每个进程都独立的页表，当 xv6 进行进程切换时，同时也会切换页表。如图 2.3, 进程的用户内存地址从 0 开始并且能增长到 MAXVA，原则上允许进程寻址 256G 字节的地址空间。<br />\n<img data-src=\"https://s2.loli.net/2022/11/03/R93QTvmPOLdNzai.png\" alt=\"22834193-b5419f00dd561894.png\" /></p>\n<p>当一个进程向 xv6 索要更多的的用户内存时，xv6 首先使用 kalloc 分配物理内存，然后将 PTEs 添加到进程的页表中并指向新分配的物理页。xv6 在这些 PTEs 中设置 PTE_W,PTE_X,PTE_R,PTE_U 和 PTE_V s 标志。大多数进程不使用整个用户地址空间，xv6 在将不使用的 PTEs 中清楚其 PTE_V 标志。</p>\n<p>我们可以看到一些非常好的使用页表的例子。第一点，不同你进程的页表会将他们的用户地址翻译到不同的物理内存中，这样每个进程都有他们私有的地址空间。第二点，每个进程看到的地址都是从 0 开始的连续地址，但事实上物理地址可能不是连续的。第三点，内核使用  <code>trampoline code</code>  在每个用户地址顶部映射一个页，因此一个物理页出现在每个地址空间。</p>\n<p>图 3.4 展示了 xv6 中用户地址布局。栈是一个单独的页，展示的是由 exec 创建初始内容。包含命令行的字符串参数以及指向他们的位于栈顶的数组。如果函数  <code>main</code>  刚刚被调用，那在其下方是允许程序执行的值。</p>\n<p>为了检测用户栈溢出，xv6 在栈下放置了一个失效保护页。如果用户地址溢出，进程试图使用栈下的地址，硬件会产生一个因为无效映射而产生的页错误。一个真实操作系统可能会分配更多的内存给栈使用。</p>\n<h2 id=\"code-sbrk\"><a class=\"anchor\" href=\"#code-sbrk\">#</a> Code: sbrk</h2>\n<p><code>Sbrk</code>  是为进程缩小或增加内存的系统调用。这个系统调用基于  <code>growproc</code>  实现。 <code>grocprow</code>  调用  <code>uvmalloc</code>  还是  <code>uvmdealloc</code>   取决于  <code>n</code>  的正负。 <code>uvmalloc</code>  通过  <code>kalloc</code>  分配物理内存，通过  <code>mappages</code>  添加 PTEs 到用户页表中。 <code>uvdealloc</code>  调用  <code>uvmunmap</code> ，这使用  <code>walk</code>   查找 PTEs 并用  <code>kfree</code>  释放物理内存。</p>\n<p>xv6 使用进程页表其功能不仅仅是告诉硬件如何映射用户虚拟地址，还作为唯一记录哪个物理内存页被分配到进程中。这也是为什么释放用户内存需要查询用户页表。</p>\n<h2 id=\"code-exec\"><a class=\"anchor\" href=\"#code-exec\">#</a> Code: exec</h2>\n<p><code>Exec</code>  是一个创建用户部分地址空间的系统调用。从文件系统中的一个文件初始化用户部分的地址空间。 <code>Exec</code>  使用  <code>namei </code> 打开名为  <code>path</code>  的二进制文件，这将在第八章解释。然后，它读取 ELF 头。xv6 使用的是被广泛使用的 ELF 格式，定义在  <code>kernnel/elf.h</code> 。ELF 二进制扩  <code>ELF头</code> ， <code>elfhdr 结构</code> ，然后是一系列程序节头， <code>proghdr 结构</code> 。每个  <code>proghdr</code>  描述描述一段应用程序需要被载入内存的数据。xv6 程序仅仅只有一个程序头，但是其他系统可能会区分指令和数据。</p>\n<p>第一步是快速检查文件是否包含 ELF 二进制。一个 ELF 二进制由魔法数字  <code>0X7F， ’E‘ ，’L‘，’F‘</code>  开始。如果 ELF 头正确包含魔法数字，exec 认为这个二进制是格式正确的。</p>\n<p><code>Exec</code>  使用  <code>proc_pagetable</code>  为没有用户映射分配的分配新页表，使用  <code>uvmalloc</code>  为每个 ELF 段分配内存，使用  <code>loadseg</code>  加载每个段到内存中。 <code>loadseg</code>  使用  <code>walkaddr</code>  查找为每个 ELF 段准备写入的物理地址。使用  <code>readi</code>  从文件读取。<br />\n <code>init</code>  程序的段如下</p>\n<p>程序段头的  <code>filesz</code>  可能小于  <code>memsz</code> ，表明中间的空隙应该用 0 填满。对 init 程序来说， <code>filesz</code>  是 2112 字节并且  <code>memsz</code>  是 2136 字节，因此  <code>uvmalloc</code>  分配足够的能容纳 2136 字节的物理内存，但仅仅从 init 中读取 2112 字节。</p>\n<p>现在  <code>exec</code>  分配和初始化用户栈。它只分配一个栈页。 <code>Exec</code>  依次拷贝参数字符串到栈顶，将指针记录在  <code>ustack</code>  中。然后在末尾放置一个空指针将来传递  <code>argv</code>  给  <code>main</code>  函数。前三个块是程序返回值，argc 和  argv 指针。</p>\n<p><code>Exec</code>  在堆栈页的下方放置一个不可访问的页，这样当程序尝试访问多于一个页的内容时就会发生错误。这个不可访问的页允许  <code>exec</code>  处理大的参数。在这个解决方案里， <code>exec</code>  使用的 <code>copyout</code>  函数拷贝参数到栈时会注意到目标页不可访问并返回 -1。</p>\n<p>在准备新的内存镜像期间，如果  <code>exec</code>  检测到类似程序段错误的问题，将会跳到  <code>bad</code>  标志并返回 -1。 <code>exec</code>  必须等待释放旧的镜像知道系统调用完成。如果旧的镜像消失了，系统调用不能返回 -1。唯一的造成  <code>exec</code>  错误的原因是创建镜像期间发生错误。一旦镜像创建完成， <code>exec</code>  提交新的也表并释放旧的。</p>\n<p><code>Exec</code>  从 ELF 文件加载字节到内存的指定位置，该位置在 ELF 文件中指定。用户或者进程能在 ELF 文件中覆盖任意地址。因此  <code>exec</code>  是有风险的，因为 ELF 文件中的地址可能有意或无意的指向内核。结果可鞥造成内核隔离机制的崩溃。xv6 做了一个数字检查来避免这种风险。例如  <code>if(ph.vaddr + ph.memsz &lt; ph.vaddr)</code>  检查加法溢出。这个危险是用户可能构造了一个 ELF 二进制，它的  <code>ph.vaddr</code>  只想用户选择的地址，而  <code>ph.memsz</code>  大于加法溢出到 0x1000，这将被认为是有效值。旧版本的 xv6 中用户地址空间包含内核（但在用户模式下不可读写），用户能够修改内核内存并将 ELF 数据拷贝到内核。在 risc-v 的 xv6 上这不会发生，因为内核有自己独立的页表。 <code>loadseg</code>  加载到进程的页表而不是内核的。<br />\n内核的开发者很容易忽略这些重要的检查。现实的内核也有很长的历史时期缺少这些检查，而能让用户程序获取内核权限。就像 xv6 并没有对用户提交到内核的数据做完整的数据检验工作，这可能让一个恶意的程序攻破 xv6 的分区隔离。</p>\n<h2 id=\"real-world\"><a class=\"anchor\" href=\"#real-world\">#</a> Real world</h2>\n<p>和大多数操作系统一样，xv6 使用页表硬件进行内存保护和映射。大多数操作系统使用比 xv6 更复杂页表来组合页表和页错误例外，这将在第四章进行讨论。</p>\n<p>xv6 简单的使用内核虚拟地址和物理地址的直接映射。并假设物理 RAM 在 0x8000000，内核会加载在这里。这在 QEMU 是好的，但在真实的硬件上这不是个好主意。真是的物理 RAM 和设备在物理地址上是不可预测的，所以可能没有 0x8000000 的 RAM 让内核加载。更严格的内核设计是利用页表将任意物理内存布局映射成可预测的虚拟内核地址布局。</p>\n<p>RISC-V 支持物理地址保护，但 xv6 没有使用这个特性。</p>\n<p>在有更多内存的机器上，让 RISC-V 支持  <code>super pages</code>  是有意义的。 <code>small pages</code>  在物理内存小的时候更有意义， 能在更细粒度上分配和页输出到磁盘。例如，如果一个程序仅仅使用 8 KB 内存，给它整个 4MB 的物理内存是浪费的。更大的页在更多 RAM 上有意义，减少页表操作的开销。</p>\n<p>xv6 的内核缺少类似  <code>malloc</code>  的动态分配小对象的分配器。这阻止了内核为动态分配器配套的复杂数据结构。</p>\n<p>内存分配一直是一个热门话题，其基本问题是如何有效使用有限的内存和应对未知的请求。今天人们更关注速度而不是空间效率。除此之外，一个精心制作的内核应该能够分配不同大小的小块而不是像 xv6 一样只能分配 4096 字节的块。一个真正的内核的分配器能够像处理大块一样处理小块。</p>\n<h2 id=\"练习\"><a class=\"anchor\" href=\"#练习\">#</a> 练习</h2>\n<ol>\n<li>解析 RISC-V 的设备树以找到计算机拥有的物理内存量。</li>\n<li>写一个用户程序，使用  <code>sbrk</code>  增长他的地址空间。运行这个程序，并在调用 sbrk 前后分别打印页表。</li>\n<li>修改 xv6 在内核中使用  <code>super pages</code></li>\n<li>修改 xv6 当用户程序取消一个空指针的引用时，收到例外。也就是说，修改 xv6，让虚拟地址 0 不被映射到用户程序中。</li>\n<li>Unix 传统上实现  <code>exec</code>  包括对 shell 脚本的特殊处理，如果一个文件以  <code>#!</code>  开头，第一行被当做一个程序来解释这个文件。例如，如果  <code>exec</code>  运行  <code>myprog arg1</code>  并且  <code>myprog</code>  的第一行是  <code>#!/interp</code> ，exec 将会运行  <code>interp</code>  myprog args1。在 xv6 中实现这个约定的支持。</li>\n<li>实现内核随机地址空间。</li>\n</ol>\n",
            "tags": [
                "xv6",
                "xv6-book中文翻译"
            ]
        },
        {
            "id": "https://i.merore.com/xv6/xv6-book-translate/chapter-2-operating-system-organization/",
            "url": "https://i.merore.com/xv6/xv6-book-translate/chapter-2-operating-system-organization/",
            "title": "Chapter 2 操作系统组成",
            "date_published": "2022-11-03T01:09:12.000Z",
            "content_html": "<h1 id=\"chapter-2-操作系统组成\"><a class=\"anchor\" href=\"#chapter-2-操作系统组成\">#</a> Chapter 2 操作系统组成</h1>\n<p>操作系统的一个关键要求就是要在同一时刻支持许多活动。例如，可以使用系统调用 <code>fork</code>  开始一个新的线程。操作系统必须在这些进程上时间共享计算机资源。例如，即使进程比 CPU 多，操作系统必须确保所有的进程都能运行。操作系统必须确保隔离这些进程。因此，如果一个进程有错误和失败，它不应该影响到那些不依赖它的进程。完全的隔离，也不行，因为进程间还需要保持一定的交互，pipline 是一个例子。因此操作系统必须满足三个需求，资源复用，隔离和交互。</p>\n<p>本章概述了如何组织操作系统来实现这三个要求。其实实现的方式有很多，但本章聚焦于宏内核上的主流设计，这也被用于许多 UNIX 操作系统。本章还提供了 XV6 进程的概念，这是 XV6 中的隔离单元，以及 XV6 启动时创建的地一个进程。</p>\n<p>XV6 运行于多核 RISC-V 微处理器上，大多数低层功能是专属于 RISC-V，RISC-V 是一个 64 位 CPU，使用 LP64 编写，意味着这个 C 语言中  <code>long</code>  和  <code>pointers</code>  是 64 位的，而不是 32 位。本书假定读者在一些架构上做了机器语言级别的编程，并会介绍 RISC-V 提出的一些特有的概念。关于 RISC-V 有这些书籍。指令手册和特权指令手册。</p>\n<p>在计算机上，CPU 是被硬件包围的，大多数硬件都是输入输出接口。XV6 是为 qemu 的 <code>-machine virt</code>  编写的。这包括 RAM，包含引导代码的 ROM，屏幕和键盘的链接，和磁盘存储。</p>\n<h2 id=\"抽象物理资源\"><a class=\"anchor\" href=\"#抽象物理资源\">#</a> 抽象物理资源</h2>\n<p>人们对操作系统的第一个问题是，为什么要使用它。是的，可以将系统调用实现为库程序可链接的库。这样的话，每个应用程序甚至能有自己需要的库。应用程序能够直接与硬件资源交互，并且用最好的方式来使用这些资源。一些嵌入式设备上的操作系统和实时操作系统是用这种方式组织的。</p>\n<p>这种库的缺点是，如果不仅仅是一个应用程序在运行，这些应用程序必须正常运行。例如，每个应用程序必须周期性的让出 CPU 来让其他应用程序运行。这样一种时间共享的方案是 OK 的，如果应用程序之间互相信任并且没有错误。更通常的情况是应用程序之间不会互相信任并且有错误，因此需要比这种合作方式更强一些的隔离性。</p>\n<p>为了实现更强的隔离性，一种有效的方式是不允许应用程序直接访问硬件资源，而是把资源抽象成服务。例如，Unix 应用程序仅通过  <code>open</code> ， <code>read</code> ， <code>write</code>  和 <code>close</code>  系统调用交互。而不是直接从硬盘上读写。通过路径名为应用程序提供便利，允许操作系统管理磁盘。即使不考虑隔离，需要交互的应用程序也会发现，相较于直接使用硬盘，使用文件系统是一种更方便的抽象形式。</p>\n<p>同样，UNIX 将选择 CPU，根据需要保存和回复寄存器透明。这样应用程序不需要关心时间共享的问题。这种透明话允许操作系统共享 CPU 即使一些程序无限循环。</p>\n<p>另一个例子，UNIX 进程使用  <code>exec</code>  建立内存镜像，而不是直接使用物理内存。让操作系统决定将进程放在内存哪一块。如果内存紧张，操作系统还会将进程的数据保存到硬盘上。  <code>Exec</code>  还为用户提供存储可执行文件镜像到文件系统的便利。</p>\n<p>UNIX 进程间的许多交互都是通过文件描述副进行的。文件描述符不仅抽象了许多细节，还定义了简单的交互方式。例如，如果 pipeline 的一端应用程序崩溃，内核将生成一个 end-of-file 的信号给 pipeline 的下一个进程。</p>\n<p>系统调用是经过精心设计的，即满足了程序交互，又提供了强隔离性。UNIX 接口不是唯一抽象资源的方法，但被证明是一种很好的方法。</p>\n<h2 id=\"用户模式特权模式和系统调用\"><a class=\"anchor\" href=\"#用户模式特权模式和系统调用\">#</a> 用户模式，特权模式和系统调用</h2>\n<p>强隔离性需要在应用程序和操作系统间有一个很明确的边界。如果一个应用程序错误，我们不希望操作系统也挂了或者其他应用程序也挂了。相反，操作系统应该清除这些失败的程序并且继续运行其他程序。为了实现这个强隔离性，操作系统必须让应用程序不能修改操作系统的数据和指令。应用程序也不能访问其他进程的内存区域。</p>\n<p>CPU 为这种强隔离性提供了硬件支持。例如 RISC-V 有三种 CPU 运行模式。 <code>machine mode</code> ， <code>supervisor mod</code> ， <code>user mode</code> 。 机器模式的指令有所有的权限。CPU 从机器模式启动，i 机器模式大多被用来配置计算机。XV6 在机器模式执行很少的代码然后切换到监管者模式。</p>\n<p>监管者模式的 CPU 允许执行特权指令，例如，启用或禁用中断，读写保存页表的寄存器等等。如果一个应用程序尝试执行特权指令，CPU 不执行这个指令，而是切换到监管模式，让监管模式程序终止掉这个进程，因为他做了不该做的事。应用程序仅运行用户模式的指令，称为运行在用户空间。同样的，在监管者模式下运行特权指令被称为运行在内核空间。运行在内核空间的程序被成为内核。</p>\n<p>一个应用程序想调用内核函数必须陷入内核。CPU 提供了特殊的指令将 CPU 从用户模式变为监管者模式，并在内核指定的入口陷入内核。（RISC-V 使用 ecall 指令）。一旦 CPU 且的换到检查者模式，内核能够检查系统调用参数，决定程序是否被允许执行这个操作，然后阻止或者执行。内核控制陷入监管者模式的入口是很重要的，如果应用程序能决定内核入口，恶意的应用程序能跳过参数检查。</p>\n<h2 id=\"内核组织结构\"><a class=\"anchor\" href=\"#内核组织结构\">#</a> 内核组织结构</h2>\n<p>一个关键的问题是哪操作系统的哪一部分应该应该跑在监管者模式下（监管者模式太难打了，后文简称 s-mod），一种可能是整个操作系统都驻留在 s-mod。这种方式称为 <code>宏内核</code> 。</p>\n<p>这种组织方式下，整个操作系统运行在所有硬件权限下。很方便操作系统设计因为不需要决定哪一部分操作系统不需要全部的硬件权限。此外，操作系统的不同部分也更易于合作。例如，操作系统有一个缓冲区能在文件系统和虚拟内存间共享。</p>\n<p>这种宏内核的组织方式的缺点在于系统不同部分的接口是混杂在一起的。因此，系统开发者很容易造成错误。在宏内核中，错误是致命的，因为在 s-mod 中错误会导致内核崩溃。如果内核崩溃，计算机会停止工作，上边运行的的应用程序也会失败。计算机必须重启。</p>\n<p>为了减少内核错误的风险，OS 设计者能减少在 s-mod 下运行的代码，并以用户模式执行大部分操作系统。这种内核组织形式称为 <code>微内核</code> 。</p>\n<p>图示是一个微内核设计，图中，文件系统以用户模式运行。OS 服务以进程的方式运行被成为服务。为了允许应用与文件系统交互，内核提供进程内部通信机制让两个用户态的进程通信。例如，如果一个应用程序比如 shell 想读写文件，他会发消息给文件系统并等待回应。</p>\n<p>在微内核里，内核接口由很少的低层函数组成用于启动应用，发送消息，访问设备等等。这种组织方式允许内核相对简单，让操作系统大部分运行在用户态。</p>\n<p>XV6 和大多数 UNIX 操作系统一样，是以宏内核的方式实现的。因此，XV6 的内核接口对应的就是操作系统接口，内核实现了一个完整的操作系统。进行 XV6 没有提供很多服务，他的内核也比很多微内核小，但在概念上是宏内核。</p>\n<h2 id=\"code-xv6-组织结构\"><a class=\"anchor\" href=\"#code-xv6-组织结构\">#</a> Code: xv6 组织结构</h2>\n<p>xv6 的内核在  <code>kernel/</code>  子目录下。源码以文件组织，遵循粗略的模块化概念。内部模块接口定义在  <code>kernel/defs.h</code> 。</p>\n<h2 id=\"进程概述\"><a class=\"anchor\" href=\"#进程概述\">#</a> 进程概述</h2>\n<p>xv6 中的隔离单元是  <code>进程</code> 。进程的抽象可以一个进程破坏或监视另一个进程，CPU，文件描述符等等。也能防止进程破坏内核本身。使得进程不能颠覆内核的隔离机制。内核实现进程抽象必须相当小心，因为有缺陷或者恶意的应用程序可能导致内核或者硬件做一些坏事。内核用来实现进程的机制包括<br />\n用户 / 监关 模式标签，地址空间和线程时间分片。</p>\n<p>为了帮助加强隔离，抽象进程为应用程序提供了一种假象，让它拥有私有机器。提供了其他程序不可读写的私有的内存系统和地址空间。进程还提供程序有自己的 CPU 执行程序指令。</p>\n<p>XV6 使用页表（硬件实现）为每个进程赋予他们自己的地址空间。RISC-V 页表翻译一个 <code>虚拟地址</code> 到 <code>物理地址</code> 。</p>\n<p>XV6 为每个进程维护一个单独的页表，用于定义该进程的地址空间。如图所示，一个包含  <code>user memory</code>  的地址空间从虚拟地址 0 开始。首先是指令，然后是全局变量，然后是栈，最后是 heap 区域（用于 malloc）。有许多因素会限制进程地址空间的最大值: RISC-V 上指针是 64 位宽，硬件仅使用低 39 位用于查询页表。XV6 进使用其中 38 位。因此，最大的地址空间是 2 的 38 次方，即 256G。这在  <code>kernel/rsicv.h</code>  MAXVA 有定义。在地址空间顶部，XV6 预留了 <code>trampoline</code>  和页映射的  <code>trapframe</code>  用于切换到内核，这会在第四章讲到。</p>\n<p>XV6 内核为每个进程维护了许多状态，聚集在  <code>struct proc</code>  中 <code>kernel/proc.h</code> 。一个进程最重要的内核状态就是他的页表，内核栈和运行状态。我们使用符号  <code>p-&gt; xxx</code>  指向  <code>proc</code>  结构中的元素。例如  <code>p-&gt;pagatable</code>  是只想进程的页表。</p>\n<p>每个进程都有一个执行线程来执行进程的指令。一个线程能够被挂起然后恢复。为了透明的选择进程，内核挂起当前的进程然后恢复另一个线程。大多数线程中的状态存储在线程的栈中，每个进程有两个栈，用户栈和内核栈 <code>p-&gt;kstack</code> 。当进程执行用户指令时，仅使用用户栈，并且内核栈是空的。当进程进入内核时（系统调用或者中断），内核代码执行在内核栈上。当线程在内核栈运行时，用户栈仍然保留着数据，但是并不被使用。一个进程的主动使用用户栈和内核栈之间交替。内核栈是分离的并免受用户代码的影响，这样即使进程摧毁了用户栈也能运行（core dump!!!）。</p>\n<p>一个进程能够通过 RISC-V 的  <code>ecall</code>  指令进行系统调用。这个指令提供硬件特权等级改变程序计数器到内核入口。入口处的代码切换到内核栈然后执行实现该系统调用耳朵内核指令。当系统调用完成，内核切换到用户栈并通过  <code>sret</code>  指令返回到用户空间，降低硬件特权等级，回复执行系统调用后的指令。一个进程的线程能够在内核中阻塞等待 IO，然后当 IO 完成后恢复。<br />\n <code>p-&gt;state</code>  表示程序是被分配，等待运行，运行中，等待 IO 还是退出。<br />\n <code>p-&gt;pagetable</code>  以 RISC-V 硬件期望的方式保存进程页表。XV6 让分页硬件在用户执行应用时使用进程的  <code>p-&gt;pagetable</code> 。进程页表还记录了存储进程内存的物理页。</p>\n<h2 id=\"code-xv6-的启动和第一个进程\"><a class=\"anchor\" href=\"#code-xv6-的启动和第一个进程\">#</a> Code: xv6 的启动和第一个进程</h2>\n<p>为了让 xv6 更具体，我们将概述内核如何启动的和运行的地一个程序。子章节将更消息的描述这个机制的实现细节。</p>\n<p>当 RISC-V 计算机启动时，它自身初始化并且运行一个内存中只读区域的  <code>boot loader</code> 。Boot loader 将加载 XV6 的内核到内存中，然后在机器模式下，CPU 在  <code>_entry (kernel/entry.S)</code>  处启动 XV6。RISC-V 在页硬件禁用的方式下启动，虚拟地址直接映射到物理地址。</p>\n<p>Loader 将内核加载到物理地址的 0x80000000 处。内核加载到 0x80000000 而不是 0xx 的原因是前边的要留给 IO 设备。</p>\n<p>_entry 处的指令设置一个栈让 xv6 能够运行 C 代码。XV6 声明一个初始化的栈空间 <code>stack0 </code> 在  <code>statc.c (kernel/start.c)</code> 。__entry 将栈指针寄存器 sp 指向  <code>stack0+4096</code>  的盏顶，因为 RISC-V 的栈是向下增长的。现在内核有栈空间了，_entry 就能调用  <code>start (kernel/start.c)</code>  的 C 代码。</p>\n<p><code>start</code>  函数进行一些仅在 m-mod 才允许的配置，然后切换到 s-mod。为了进入 s-mod，RISC-V 提供了 mret 指令。这个指令最常用于 s-mod 到 m-mod 调用之后的返回。 <code>start</code>  并不从这个调用返回，而是设置一些东西，在  <code>mstatus</code>  寄存器中设置 s-mod，通过把  <code>main</code>  函数的返回地址放入  <code>mepc</code>  寄存器来返回到 main 函数，通过将 0 写入页表寄存器  <code>stap</code>  来禁用虚拟地址翻译，and delegates all interrupts and exceptions to supervisor mode.（这句不会）。</p>\n<p>在跳到 s-mod 之前， <code>start</code>  还要执行一个任务，对时钟芯片进行编程以产生时钟中断。有了这个， <code>start</code>  通过  <code>mret</code>  指令返回到 s-mod。这也将让程序计数器调到  <code>main (kernel/main.c)</code> 。</p>\n<p>当 main 函数初始化一系列的设备和子系统后，它通过调用  <code>userinit (kernel/proc.c)</code>  创建第一个进程。第一个进程是用 RISC-V 汇编写的小程序， <code>initcode.S (user/initcode.S)</code> ，通过调用  <code>exec</code>  重新进入内核。就像我们第一章讲的那样， <code>exec</code>  使用新的程序，在这个例子中是  <code>init</code> ，替换当前进程的内存和寄存器。一旦内核完成  <code>exec</code> ，将返回用户空间的  <code>init</code>  进程。 <code>Init (user/init.c)</code>  创建一个新的控制台并将其以文件描述符 0 1 2 的形式打开。然后在这个控制台中启动一个 shell。系统就启动了。</p>\n<h2 id=\"real-world\"><a class=\"anchor\" href=\"#real-world\">#</a> Real world</h2>\n<p>在现实中，我们能找到宏内核和微内核。许多 UNIX 内核是宏内核。例如 Linux，尽管一些系统功能在用户层。像 L4，Minix 和 QNX 是微内核，并在嵌入式系统中广泛使用。<br />\n大多数操作系统有进程的概念，兵器大多数进程和 XV6 是相似的，现代操作系统还支持在一个进程中拥有多线程，允许一个线程利用多个 CPU。在一个进程中支持多线程设计相当多，XV6 还没有，包括潜在的一些接口变化，控制进程线程共享。</p>\n",
            "tags": [
                "xv6",
                "xv6-book中文翻译"
            ]
        }
    ]
}